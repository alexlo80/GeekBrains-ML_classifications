{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашняя работа 4-го урока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для любой выборки можно построить решающее дерево,не допускающее на ней ни одной ошибки, в каждом листе которого находится ровно по\n",
    "одному объекту выборки. Скорее всего, это дерево будет переобученным и не сможет показать хорошее качество на новых данных.\n",
    "\n",
    "Чтобы избежать переобучения, мы должны добавить параметры регуляризации в модель.\n",
    "Можно придумать большое количество способов регулярицации. \n",
    "Перечислим некоторые:\n",
    "* Ограничение максимальной глубины дерева (max_depth).\n",
    "* Ограничение минимального числа объектов в листе (min_samples_leaf).\n",
    "* Ограничение максимального количества листьев в дереве.\n",
    "* Ограничение в случае, если все объекты в листе относятся к одному классу.\n",
    "* Требование, что функционал качества при дроблении улучшался как минимум на s процентов.\n",
    "\n",
    "\n",
    "С помощью грамотного выбора подобных критериев и их параметров можно существенно повлиять на качество дерева.\n",
    "Тем не менее, такой подбор является трудозатратным и требует проведения кросс-валидации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### По какому принципу рассчитывается \"важность признака (feature_importance)\" в ансамблях деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под важностью характеристик подразумеваем те, которые оказали наибольшее влияние на объяснение конкретного наблюдения, введенного в модель. Например, в случае кредитного рейтинга мы могли бы сказать, что эти функции оказали наибольшее влияние на определение кредитного рейтинга клиента.\n",
    "\n",
    "Есть много способов рассчитать оценки важности функций и множество моделей, которые можно использовать для этой цели.\n",
    "Возможно, самый простой способ - вычислить простую статистику коэффициентов между каждой функцией и целевой переменной.\n",
    "\n",
    "\n",
    "Может быть и такое определение : отношение между количеством выборок, направляемых в узел принятия решения с участием этого признака в любом из деревьев ансамбля, и общим количеством выборок в обучающем наборе.\n",
    "Функции, участвующие в узлах верхнего уровня деревьев решений, имеют тенденцию видеть больше выборок, следовательно, они, вероятно, будут иметь большую важность.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Укажите, пожалуйста, ваш ник на kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Мой ник:AlexLo80. Результат - 0,60162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовой проект,продолжение. Прошу прощения акцент был на материалы 3-4 урока. Статистический анализ признаков сюда не перенес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Путь к файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data/course_project')\n",
    "MODELS_PATH = Path('data/course_project/models/')\n",
    "\n",
    "# input\n",
    "TRAIN_DATASET_PATH = DATA_ROOT / 'train.csv'\n",
    "TEST_DATASET_PATH =  DATA_ROOT / 'test.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для отчистки пропущенных данных через медианы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    # убьем 'renewable energy'\n",
    "    df = df[df['Purpose']!='renewable energy']\n",
    "\n",
    "    CAT_FEATURE_NAMES = []\n",
    "    # категории заполняем дамми данными\n",
    "    for cat_colname in df.select_dtypes(include='object').columns:\n",
    "        df = pd.concat([df, pd.get_dummies(df[cat_colname], prefix=cat_colname)], axis=1)\n",
    "        # делаем список категорий\n",
    "        CAT_FEATURE_NAMES.append(cat_colname)\n",
    "    \n",
    "    # находим столбцы с пропусками\n",
    "    col_wo_cat = []\n",
    "    for col in df.columns:\n",
    "        count = df[col].count()\n",
    "        if count < df.shape[0]:\n",
    "            col_wo_cat.append (col)\n",
    "    \n",
    "    # удаляем из списка, для отдельной обработки\n",
    "    col_wo_cat.remove('Years in current job')\n",
    "    \n",
    "            \n",
    "#      заполняем категорию самым  частым значением\n",
    "    df.loc[df['Years in current job'].isna(), 'Years in current job'] = df['Years in current job'].describe().top\n",
    "    \n",
    "    \n",
    "    #переводим в числа столбец категорий\n",
    "    df['Credit Score'] = pd.to_numeric(df['Credit Score'], errors='coerce')\n",
    "    \n",
    "#     заполняем медианами числовые пропуски\n",
    "    for col in col_wo_cat:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            df.loc[df[col].isna(), col] = df[col].median()\n",
    "\n",
    "    \n",
    "    # создали Id и индексировали по этому столбу\n",
    "    df['Id'] = 0\n",
    "    df['Id'] = df.index \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансировка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target(df, target_name, method):\n",
    "\n",
    "    assert method in ['over', 'under', 'tomek', 'smote'], 'Неверный метод сэмплирования'\n",
    "    \n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.argmax()\n",
    "    minor_class_name = target_counts.argmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "    if method == 'over':\n",
    "        for i in range(disbalance_coeff):\n",
    "            sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "            df = df.append(sample, ignore_index=True)\n",
    "            \n",
    "    elif method == 'under':\n",
    "        df_ = df.copy()\n",
    "        df = df_[df_[target_name] == minor_class_name]\n",
    "        tmp = df_[df_[target_name] == major_class_name]\n",
    "        df = df.append(tmp.iloc[\n",
    "            np.random.randint(0, tmp.shape[0], target_counts[minor_class_name])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    elif method == 'tomek':\n",
    "        from imblearn.under_sampling import TomekLinks\n",
    "        tl = TomekLinks()\n",
    "        X_tomek, y_tomek = tl.fit_sample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_tomek, y_tomek], axis=1)\n",
    "    \n",
    "    elif method == 'smote':\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE()\n",
    "        X_smote, y_smote = smote.fit_sample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_smote, y_smote], axis=1)\n",
    "\n",
    "    return df.sample(frac=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для вывода отчета о результатах работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred,model):\n",
    "    print(model)\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для оценки работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    get_classification_report(y_train, y_train_pred, y_test, y_test_pred,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для заполнения пропусков  с помощью модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_rfr(data, target_col):\n",
    "    \n",
    "    # Хорошо работает, если только в одном столбце отстутствуют данные\n",
    "    train = data[~data[target_col].isna()]\n",
    "    predict_data = data[data[target_col].isna()]\n",
    "\n",
    "    X = train.drop(columns=target_col)\n",
    "    y = train[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=32)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100,\n",
    "                                  max_depth=10,\n",
    "                                  random_state=42,\n",
    "                                  verbose=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"r2 на train: {r2_score(y_train, pred_train)}\")\n",
    "    print(f\"r2 на test: {r2_score(y_test, pred_test)}\")\n",
    "\n",
    "    pred = model.predict(predict_data.drop(columns=target_col))\n",
    "\n",
    "    data.loc[data[target_col].isna(), target_col] = list(pred)\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропущенных данных с помощью функции imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 на train: 0.49118028537608793\n",
      "r2 на test: 0.18245185572587053\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Credit Score                  7500 non-null   float64\n",
      " 1   Annual Income                 5943 non-null   float64\n",
      " 2   Tax Liens                     7500 non-null   float64\n",
      " 3   Number of Open Accounts       7500 non-null   float64\n",
      " 4   Years of Credit History       7500 non-null   float64\n",
      " 5   Maximum Open Credit           7500 non-null   float64\n",
      " 6   Number of Credit Problems     7500 non-null   float64\n",
      " 7   Months since last delinquent  3419 non-null   float64\n",
      " 8   Bankruptcies                  7486 non-null   float64\n",
      " 9   Current Loan Amount           7500 non-null   float64\n",
      " 10  Current Credit Balance        7500 non-null   float64\n",
      " 11  Monthly Debt                  7500 non-null   float64\n",
      " 12  Credit Default                7500 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 761.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 на train: 0.9248434731979835\n",
      "r2 на test: 0.779296187958956\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Bankruptcies                  7500 non-null   float64\n",
      " 1   Credit Score                  7500 non-null   float64\n",
      " 2   Annual Income                 5943 non-null   float64\n",
      " 3   Tax Liens                     7500 non-null   float64\n",
      " 4   Number of Open Accounts       7500 non-null   float64\n",
      " 5   Years of Credit History       7500 non-null   float64\n",
      " 6   Maximum Open Credit           7500 non-null   float64\n",
      " 7   Number of Credit Problems     7500 non-null   float64\n",
      " 8   Months since last delinquent  3419 non-null   float64\n",
      " 9   Current Loan Amount           7500 non-null   float64\n",
      " 10  Current Credit Balance        7500 non-null   float64\n",
      " 11  Monthly Debt                  7500 non-null   float64\n",
      " 12  Credit Default                7500 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 761.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 на train: 0.4054901533035765\n",
      "r2 на test: 0.041766050103018815\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Months since last delinquent  7500 non-null   float64\n",
      " 1   Bankruptcies                  7500 non-null   float64\n",
      " 2   Credit Score                  7500 non-null   float64\n",
      " 3   Annual Income                 5943 non-null   float64\n",
      " 4   Tax Liens                     7500 non-null   float64\n",
      " 5   Number of Open Accounts       7500 non-null   float64\n",
      " 6   Years of Credit History       7500 non-null   float64\n",
      " 7   Maximum Open Credit           7500 non-null   float64\n",
      " 8   Number of Credit Problems     7500 non-null   float64\n",
      " 9   Current Loan Amount           7500 non-null   float64\n",
      " 10  Current Credit Balance        7500 non-null   float64\n",
      " 11  Monthly Debt                  7500 non-null   float64\n",
      " 12  Credit Default                7500 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 761.8 KB\n",
      "r2 на train: 0.7681397305852131\n",
      "r2 на test: 0.3595983185600572\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Annual Income                 7500 non-null   float64\n",
      " 1   Months since last delinquent  7500 non-null   float64\n",
      " 2   Bankruptcies                  7500 non-null   float64\n",
      " 3   Credit Score                  7500 non-null   float64\n",
      " 4   Tax Liens                     7500 non-null   float64\n",
      " 5   Number of Open Accounts       7500 non-null   float64\n",
      " 6   Years of Credit History       7500 non-null   float64\n",
      " 7   Maximum Open Credit           7500 non-null   float64\n",
      " 8   Number of Credit Problems     7500 non-null   float64\n",
      " 9   Current Loan Amount           7500 non-null   float64\n",
      " 10  Current Credit Balance        7500 non-null   float64\n",
      " 11  Monthly Debt                  7500 non-null   float64\n",
      " 12  Credit Default                7500 non-null   int64  \n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 761.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# определелили список категорий\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                             'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                             'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score',\n",
    "                     'Credit Default']\n",
    "data = df_train[NUM_FEATURE_NAMES]\n",
    "\n",
    "def empties(df):\n",
    "#определяем категории с пропусками\n",
    "    col_wo_cat = []\n",
    "    for col in df.columns:\n",
    "        count = df[col].count()\n",
    "        if count < df.shape[0]:\n",
    "            col_wo_cat.append (col)\n",
    "    return col_wo_cat\n",
    "\n",
    "col_wo_cat = empties(data)\n",
    "for i in range (len(col_wo_cat)):\n",
    "    col_wo_cat = empties(data)\n",
    "    target_col = col_wo_cat [-1]\n",
    "    # col_wo_cat\n",
    "\n",
    "    NUM_FEATURE_full= [item for item in NUM_FEATURE_NAMES if item not in col_wo_cat]+[target_col]\n",
    "    df_reduced = data[NUM_FEATURE_full]\n",
    "\n",
    "    df_r_filled = imputer_rfr (df_reduced,target_col)\n",
    "    df_filled = df_r_filled[target_col]\n",
    "\n",
    "    df2 = data.drop([target_col], axis=1)\n",
    "    frames = [df_filled, df2]\n",
    "    data = pd.concat(frames, axis=1, join=\"inner\")\n",
    "    data.info()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели с базовыми параметрами с функцией и циклом, без масштабирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86      3770\n",
      "           1       0.82      0.20      0.33      1478\n",
      "\n",
      "    accuracy                           0.76      5248\n",
      "   macro avg       0.79      0.59      0.59      5248\n",
      "weighted avg       0.78      0.76      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.85      1617\n",
      "           1       0.79      0.21      0.33       633\n",
      "\n",
      "    accuracy                           0.76      2250\n",
      "   macro avg       0.77      0.59      0.59      2250\n",
      "weighted avg       0.77      0.76      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1581   36\n",
      "1                501  132\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      3770\n",
      "           1       0.00      0.00      0.00      1478\n",
      "\n",
      "    accuracy                           0.72      5248\n",
      "   macro avg       0.36      0.50      0.42      5248\n",
      "weighted avg       0.52      0.72      0.60      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1617\n",
      "           1       0.00      0.00      0.00       633\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.36      0.50      0.42      2250\n",
      "weighted avg       0.52      0.72      0.60      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0\n",
      "Credit Default      \n",
      "0               1617\n",
      "1                633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      3770\n",
      "           1       0.67      0.45      0.54      1478\n",
      "\n",
      "    accuracy                           0.78      5248\n",
      "   macro avg       0.74      0.68      0.70      5248\n",
      "weighted avg       0.77      0.78      0.77      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.78      1617\n",
      "           1       0.37      0.24      0.29       633\n",
      "\n",
      "    accuracy                           0.67      2250\n",
      "   macro avg       0.55      0.54      0.54      2250\n",
      "weighted avg       0.63      0.67      0.65      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1352  265\n",
      "1                479  154\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={0: 1, 1: 3.6},\n",
      "                       criterion='gini', max_depth=4, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=21, splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.30      0.45      3770\n",
      "           1       0.35      0.96      0.51      1478\n",
      "\n",
      "    accuracy                           0.48      5248\n",
      "   macro avg       0.65      0.63      0.48      5248\n",
      "weighted avg       0.78      0.48      0.47      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45      1617\n",
      "           1       0.34      0.95      0.51       633\n",
      "\n",
      "    accuracy                           0.48      2250\n",
      "   macro avg       0.64      0.62      0.48      2250\n",
      "weighted avg       0.77      0.48      0.47      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               479  1138\n",
      "1                34   599\n",
      "[16:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3770\n",
      "           1       0.99      0.84      0.91      1478\n",
      "\n",
      "    accuracy                           0.95      5248\n",
      "   macro avg       0.97      0.92      0.94      5248\n",
      "weighted avg       0.96      0.95      0.95      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      1617\n",
      "           1       0.60      0.33      0.42       633\n",
      "\n",
      "    accuracy                           0.75      2250\n",
      "   macro avg       0.69      0.62      0.63      2250\n",
      "weighted avg       0.73      0.75      0.72      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1481  136\n",
      "1                426  207\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={0: 1, 1: 3.6},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
      "               objective=None, random_state=21, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90      3770\n",
      "           1       0.69      0.99      0.81      1478\n",
      "\n",
      "    accuracy                           0.87      5248\n",
      "   macro avg       0.84      0.91      0.86      5248\n",
      "weighted avg       0.91      0.87      0.88      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73      1617\n",
      "           1       0.43      0.66      0.52       633\n",
      "\n",
      "    accuracy                           0.66      2250\n",
      "   macro avg       0.63      0.66      0.63      2250\n",
      "weighted avg       0.72      0.66      0.67      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1060  557\n",
      "1                217  416\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2BBD22C8>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      3770\n",
      "           1       0.99      0.50      0.67      1478\n",
      "\n",
      "    accuracy                           0.86      5248\n",
      "   macro avg       0.91      0.75      0.79      5248\n",
      "weighted avg       0.88      0.86      0.84      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1617\n",
      "           1       0.74      0.28      0.41       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.76      0.62      0.63      2250\n",
      "weighted avg       0.77      0.77      0.73      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1555   62\n",
      "1                453  180\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    "  \n",
    "\n",
    "def modeling (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES]\n",
    "\n",
    "# Разбиваем данные\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "\n",
    "modellist = ['LogisticRegression','model_svm','model_knn','model_tree','model_xgb','model_lgbm','model_catb']\n",
    "for mode in modellist:\n",
    "    if mode == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    elif mode == 'model_svm':\n",
    "        model = SVC()\n",
    "    elif mode == 'model_knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif mode == 'model_tree':\n",
    "        model = DecisionTreeClassifier(random_state = 21, class_weight = {0:1, 1:3.6}, max_depth = 4)\n",
    "    elif mode == 'model_xgb':\n",
    "        model = xgb.XGBClassifier(random_state = 21)#,n_estimators = 100)\n",
    "    elif mode == 'model_lgbm':\n",
    "        model = lgbm.LGBMClassifier(random_state = 21, class_weight = {0:1, 1:3.6}) #,n_estimators= 100)\n",
    "    elif mode == 'model_catb':\n",
    "        model = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "\n",
    "    preds_final[TARGET_NAME] = modeling(model,X_train, X_test, y_train, y_test)\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/{mode}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели с базовыми параметрами с функцией и циклом, без масштабирования, с балансировкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62      1478\n",
      "           1       0.63      0.72      0.67      1478\n",
      "\n",
      "    accuracy                           0.64      2956\n",
      "   macro avg       0.65      0.64      0.64      2956\n",
      "weighted avg       0.65      0.64      0.64      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67      1617\n",
      "           1       0.38      0.66      0.48       633\n",
      "\n",
      "    accuracy                           0.60      2250\n",
      "   macro avg       0.59      0.62      0.57      2250\n",
      "weighted avg       0.69      0.60      0.62      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               920  697\n",
      "1               214  419\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27      1478\n",
      "           1       0.54      1.00      0.70      1478\n",
      "\n",
      "    accuracy                           0.58      2956\n",
      "   macro avg       0.77      0.58      0.49      2956\n",
      "weighted avg       0.77      0.58      0.49      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29      1617\n",
      "           1       0.32      1.00      0.48       633\n",
      "\n",
      "    accuracy                           0.40      2250\n",
      "   macro avg       0.66      0.58      0.39      2250\n",
      "weighted avg       0.81      0.40      0.34      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               274  1343\n",
      "1                 1   632\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1478\n",
      "           1       0.74      0.77      0.75      1478\n",
      "\n",
      "    accuracy                           0.75      2956\n",
      "   macro avg       0.75      0.75      0.75      2956\n",
      "weighted avg       0.75      0.75      0.75      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65      1617\n",
      "           1       0.35      0.60      0.44       633\n",
      "\n",
      "    accuracy                           0.57      2250\n",
      "   macro avg       0.56      0.58      0.55      2250\n",
      "weighted avg       0.66      0.57      0.59      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               899  718\n",
      "1               251  382\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={0: 1, 1: 3.6},\n",
      "                       criterion='gini', max_depth=4, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=21, splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27      1478\n",
      "           1       0.54      1.00      0.70      1478\n",
      "\n",
      "    accuracy                           0.58      2956\n",
      "   macro avg       0.77      0.58      0.49      2956\n",
      "weighted avg       0.77      0.58      0.49      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.28      1617\n",
      "           1       0.32      1.00      0.48       633\n",
      "\n",
      "    accuracy                           0.40      2250\n",
      "   macro avg       0.66      0.58      0.38      2250\n",
      "weighted avg       0.81      0.40      0.34      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               267  1350\n",
      "1                 0   633\n",
      "[16:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1478\n",
      "           1       0.99      0.99      0.99      1478\n",
      "\n",
      "    accuracy                           0.99      2956\n",
      "   macro avg       0.99      0.99      0.99      2956\n",
      "weighted avg       0.99      0.99      0.99      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.61      0.70      1617\n",
      "           1       0.41      0.68      0.51       633\n",
      "\n",
      "    accuracy                           0.63      2250\n",
      "   macro avg       0.62      0.65      0.61      2250\n",
      "weighted avg       0.71      0.63      0.65      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               988  629\n",
      "1               201  432\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={0: 1, 1: 3.6},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
      "               objective=None, random_state=21, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84      1478\n",
      "           1       0.78      1.00      0.88      1478\n",
      "\n",
      "    accuracy                           0.86      2956\n",
      "   macro avg       0.89      0.86      0.86      2956\n",
      "weighted avg       0.89      0.86      0.86      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.39      0.54      1617\n",
      "           1       0.36      0.88      0.51       633\n",
      "\n",
      "    accuracy                           0.53      2250\n",
      "   macro avg       0.63      0.64      0.53      2250\n",
      "weighted avg       0.75      0.53      0.53      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               628  989\n",
      "1                73  560\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2618A508>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1478\n",
      "           1       0.92      0.91      0.91      1478\n",
      "\n",
      "    accuracy                           0.91      2956\n",
      "   macro avg       0.91      0.91      0.91      2956\n",
      "weighted avg       0.91      0.91      0.91      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72      1617\n",
      "           1       0.41      0.65      0.51       633\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.62      0.65      0.61      2250\n",
      "weighted avg       0.71      0.64      0.66      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1034  583\n",
      "1                221  412\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    "  \n",
    "\n",
    "def modeling (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES]\n",
    "\n",
    "# Разбиваем данные\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "# балансировка\n",
    "df_for_balancing = pd.concat([X_train, y_train], axis=1)\n",
    "df_balanced = balance_df_by_target(df_for_balancing, TARGET_NAME, method='under')\n",
    "df_balanced[TARGET_NAME].value_counts()\n",
    "X_train_balanced = df_balanced.drop(columns=TARGET_NAME)\n",
    "y_train_balanced = df_balanced[TARGET_NAME]\n",
    "\n",
    "\n",
    "modellist = ['LogisticRegression','model_svm','model_knn','model_tree','model_xgb','model_lgbm','model_catb']\n",
    "for mode in modellist:\n",
    "    if mode == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    elif mode == 'model_svm':\n",
    "        model = SVC()\n",
    "    elif mode == 'model_knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif mode == 'model_tree':\n",
    "        model = DecisionTreeClassifier(random_state = 21, class_weight = {0:1, 1:3.6}, max_depth = 4)\n",
    "    elif mode == 'model_xgb':\n",
    "        model = xgb.XGBClassifier(random_state = 21)#,n_estimators = 100)\n",
    "    elif mode == 'model_lgbm':\n",
    "        model = lgbm.LGBMClassifier(random_state = 21, class_weight = {0:1, 1:3.6}) #,n_estimators= 100)\n",
    "    elif mode == 'model_catb':\n",
    "        model = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "\n",
    "    preds_final[TARGET_NAME] = modeling(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/Bal/{mode}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели с базовыми параметрами с функцией и циклом, с масштабированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       0.98      0.19      0.32      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.87      0.59      0.59      5248\n",
      "weighted avg       0.82      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       0.98      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.87      0.60      0.59      2250\n",
      "weighted avg       0.82      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1614    3\n",
      "1                510  123\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       1.00      0.20      0.34      1478\n",
      "\n",
      "    accuracy                           0.78      5248\n",
      "   macro avg       0.88      0.60      0.60      5248\n",
      "weighted avg       0.83      0.78      0.72      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       0.98      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.87      0.60      0.59      2250\n",
      "weighted avg       0.82      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1614    3\n",
      "1                510  123\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87      3770\n",
      "           1       0.76      0.43      0.55      1478\n",
      "\n",
      "    accuracy                           0.80      5248\n",
      "   macro avg       0.79      0.69      0.71      5248\n",
      "weighted avg       0.80      0.80      0.78      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      1617\n",
      "           1       0.51      0.30      0.38       633\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.64      0.60      0.60      2250\n",
      "weighted avg       0.69      0.72      0.70      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1437  180\n",
      "1                442  191\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={0: 1, 1: 3.6},\n",
      "                       criterion='gini', max_depth=4, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=21, splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.30      0.45      3770\n",
      "           1       0.35      0.96      0.51      1478\n",
      "\n",
      "    accuracy                           0.48      5248\n",
      "   macro avg       0.65      0.63      0.48      5248\n",
      "weighted avg       0.78      0.48      0.47      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.30      0.45      1617\n",
      "           1       0.34      0.95      0.51       633\n",
      "\n",
      "    accuracy                           0.48      2250\n",
      "   macro avg       0.64      0.62      0.48      2250\n",
      "weighted avg       0.77      0.48      0.47      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               479  1138\n",
      "1                34   599\n",
      "[16:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3770\n",
      "           1       0.99      0.84      0.91      1478\n",
      "\n",
      "    accuracy                           0.95      5248\n",
      "   macro avg       0.97      0.92      0.94      5248\n",
      "weighted avg       0.96      0.95      0.95      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      1617\n",
      "           1       0.61      0.33      0.42       633\n",
      "\n",
      "    accuracy                           0.75      2250\n",
      "   macro avg       0.69      0.62      0.63      2250\n",
      "weighted avg       0.73      0.75      0.72      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1482  135\n",
      "1                426  207\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={0: 1, 1: 3.6},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
      "               objective=None, random_state=21, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.90      3770\n",
      "           1       0.69      0.99      0.81      1478\n",
      "\n",
      "    accuracy                           0.87      5248\n",
      "   macro avg       0.84      0.91      0.86      5248\n",
      "weighted avg       0.91      0.87      0.88      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73      1617\n",
      "           1       0.43      0.65      0.52       633\n",
      "\n",
      "    accuracy                           0.66      2250\n",
      "   macro avg       0.63      0.65      0.62      2250\n",
      "weighted avg       0.71      0.66      0.67      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1062  555\n",
      "1                221  412\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2DAD7B48>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      3770\n",
      "           1       0.99      0.50      0.67      1478\n",
      "\n",
      "    accuracy                           0.86      5248\n",
      "   macro avg       0.91      0.75      0.79      5248\n",
      "weighted avg       0.88      0.86      0.84      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86      1617\n",
      "           1       0.74      0.28      0.41       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.76      0.62      0.63      2250\n",
      "weighted avg       0.77      0.77      0.73      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1555   62\n",
      "1                453  180\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    "  \n",
    "\n",
    "def modeling (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES]\n",
    "\n",
    "# Масштабируем данные\n",
    "scaler = StandardScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "df = df_norm.copy()\n",
    "\n",
    "# Разбиваем данные\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "\n",
    "modellist = ['LogisticRegression','model_svm','model_knn','model_tree','model_xgb','model_lgbm','model_catb']\n",
    "for mode in modellist:\n",
    "    if mode == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    elif mode == 'model_svm':\n",
    "        model = SVC()\n",
    "    elif mode == 'model_knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif mode == 'model_tree':\n",
    "        model = DecisionTreeClassifier(random_state = 21, class_weight = {0:1, 1:3.6}, max_depth = 4)\n",
    "    elif mode == 'model_xgb':\n",
    "        model = xgb.XGBClassifier(random_state = 21)#,n_estimators = 100)\n",
    "    elif mode == 'model_lgbm':\n",
    "        model = lgbm.LGBMClassifier(random_state = 21, class_weight = {0:1, 1:3.6}) #,n_estimators= 100)\n",
    "    elif mode == 'model_catb':\n",
    "        model = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "\n",
    "    preds_final[TARGET_NAME] = modeling(model,X_train, X_test, y_train, y_test)\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/Scal/{mode}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели с базовыми параметрами с функцией и циклом, с масштабированием и балансировкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62      1478\n",
      "           1       0.63      0.68      0.66      1478\n",
      "\n",
      "    accuracy                           0.64      2956\n",
      "   macro avg       0.64      0.64      0.64      2956\n",
      "weighted avg       0.64      0.64      0.64      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67      1617\n",
      "           1       0.37      0.64      0.47       633\n",
      "\n",
      "    accuracy                           0.59      2250\n",
      "   macro avg       0.58      0.60      0.57      2250\n",
      "weighted avg       0.68      0.59      0.61      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               926  691\n",
      "1               231  402\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      1478\n",
      "           1       0.67      0.70      0.69      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.68      0.68      0.68      2956\n",
      "weighted avg       0.68      0.68      0.68      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66      1617\n",
      "           1       0.36      0.64      0.46       633\n",
      "\n",
      "    accuracy                           0.58      2250\n",
      "   macro avg       0.58      0.60      0.56      2250\n",
      "weighted avg       0.67      0.58      0.60      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               906  711\n",
      "1               231  402\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      1478\n",
      "           1       0.77      0.72      0.74      1478\n",
      "\n",
      "    accuracy                           0.75      2956\n",
      "   macro avg       0.75      0.75      0.75      2956\n",
      "weighted avg       0.75      0.75      0.75      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68      1617\n",
      "           1       0.37      0.60      0.46       633\n",
      "\n",
      "    accuracy                           0.60      2250\n",
      "   macro avg       0.58      0.60      0.57      2250\n",
      "weighted avg       0.67      0.60      0.62      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               964  653\n",
      "1               254  379\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={0: 1, 1: 3.6},\n",
      "                       criterion='gini', max_depth=4, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=21, splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29      1478\n",
      "           1       0.55      1.00      0.71      1478\n",
      "\n",
      "    accuracy                           0.58      2956\n",
      "   macro avg       0.77      0.58      0.50      2956\n",
      "weighted avg       0.77      0.58      0.50      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.28      1617\n",
      "           1       0.32      1.00      0.48       633\n",
      "\n",
      "    accuracy                           0.40      2250\n",
      "   macro avg       0.66      0.58      0.38      2250\n",
      "weighted avg       0.81      0.40      0.34      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               267  1350\n",
      "1                 0   633\n",
      "[16:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1478\n",
      "           1       1.00      0.99      0.99      1478\n",
      "\n",
      "    accuracy                           0.99      2956\n",
      "   macro avg       0.99      0.99      0.99      2956\n",
      "weighted avg       0.99      0.99      0.99      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.59      0.69      1617\n",
      "           1       0.39      0.66      0.49       633\n",
      "\n",
      "    accuracy                           0.61      2250\n",
      "   macro avg       0.60      0.63      0.59      2250\n",
      "weighted avg       0.70      0.61      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               958  659\n",
      "1               215  418\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={0: 1, 1: 3.6},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
      "               objective=None, random_state=21, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85      1478\n",
      "           1       0.79      1.00      0.88      1478\n",
      "\n",
      "    accuracy                           0.87      2956\n",
      "   macro avg       0.90      0.87      0.87      2956\n",
      "weighted avg       0.90      0.87      0.87      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.39      0.54      1617\n",
      "           1       0.36      0.87      0.51       633\n",
      "\n",
      "    accuracy                           0.53      2250\n",
      "   macro avg       0.62      0.63      0.53      2250\n",
      "weighted avg       0.74      0.53      0.53      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               633  984\n",
      "1                82  551\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2B9CAA48>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1478\n",
      "           1       0.90      0.91      0.90      1478\n",
      "\n",
      "    accuracy                           0.90      2956\n",
      "   macro avg       0.90      0.90      0.90      2956\n",
      "weighted avg       0.90      0.90      0.90      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.61      0.70      1617\n",
      "           1       0.40      0.67      0.50       633\n",
      "\n",
      "    accuracy                           0.63      2250\n",
      "   macro avg       0.61      0.64      0.60      2250\n",
      "weighted avg       0.71      0.63      0.64      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               983  634\n",
      "1               209  424\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    "  \n",
    "\n",
    "def modeling (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES]\n",
    "\n",
    "# Масштабируем данные\n",
    "scaler = StandardScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "df = df_norm.copy()\n",
    "\n",
    "# Разбиваем данные\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "# балансировка\n",
    "df_for_balancing = pd.concat([X_train, y_train], axis=1)\n",
    "df_balanced = balance_df_by_target(df_for_balancing, TARGET_NAME, method='under')\n",
    "df_balanced[TARGET_NAME].value_counts()\n",
    "X_train_balanced = df_balanced.drop(columns=TARGET_NAME)\n",
    "y_train_balanced = df_balanced[TARGET_NAME]\n",
    "\n",
    "modellist = ['LogisticRegression','model_svm','model_knn','model_tree','model_xgb','model_lgbm','model_catb']\n",
    "for mode in modellist:\n",
    "    if mode == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    elif mode == 'model_svm':\n",
    "        model = SVC()\n",
    "    elif mode == 'model_knn':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif mode == 'model_tree':\n",
    "        model = DecisionTreeClassifier(random_state = 21, class_weight = {0:1, 1:3.6}, max_depth = 4)\n",
    "    elif mode == 'model_xgb':\n",
    "        model = xgb.XGBClassifier(random_state = 21)#,n_estimators = 100)\n",
    "    elif mode == 'model_lgbm':\n",
    "        model = lgbm.LGBMClassifier(random_state = 21, class_weight = {0:1, 1:3.6}) #,n_estimators= 100)\n",
    "    elif mode == 'model_catb':\n",
    "        model = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "\n",
    "    preds_final[TARGET_NAME] = modeling(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/Scal/Bal/{mode}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели  с подбором параметров (RandomSearchCV), без масштабирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'max_iter': 377.795918367347, 'C': 1e-09}\n",
      "Best Score 0.7675317082028237\n",
      "LogisticRegression(C=1e-09, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=377.795918367347, multi_class='auto', n_jobs=None,\n",
      "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       0.95      0.19      0.31      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.85      0.59      0.59      5248\n",
      "weighted avg       0.81      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86      1617\n",
      "           1       0.91      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.83      0.59      0.59      2250\n",
      "weighted avg       0.80      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1605   12\n",
      "1                512  121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 0.0001}\n",
      "Best Score 0.7183690589677243\n",
      "SVC(C=0.0001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      3770\n",
      "           1       0.00      0.00      0.00      1478\n",
      "\n",
      "    accuracy                           0.72      5248\n",
      "   macro avg       0.36      0.50      0.42      5248\n",
      "weighted avg       0.52      0.72      0.60      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1617\n",
      "           1       0.00      0.00      0.00       633\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.36      0.50      0.42      2250\n",
      "weighted avg       0.52      0.72      0.60      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0\n",
      "Credit Default      \n",
      "0               1617\n",
      "1                633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_neighbors': 63, 'leaf_size': 67}\n",
      "Best Score 0.7216080620999591\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=67, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=63, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84      3770\n",
      "           1       0.60      0.07      0.13      1478\n",
      "\n",
      "    accuracy                           0.73      5248\n",
      "   macro avg       0.67      0.53      0.48      5248\n",
      "weighted avg       0.69      0.73      0.64      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.83      1617\n",
      "           1       0.53      0.06      0.11       633\n",
      "\n",
      "    accuracy                           0.72      2250\n",
      "   macro avg       0.63      0.52      0.47      2250\n",
      "weighted avg       0.67      0.72      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0   1\n",
      "Credit Default          \n",
      "0               1583  34\n",
      "1                595  38\n",
      "Best Params {'min_samples_leaf': 5, 'max_depth': 30, 'class_weight': {1: 59.59183673469387}}\n",
      "Best Score 0.6030870216532752\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={1: 59.59183673469387},\n",
      "                       criterion='gini', max_depth=30, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=5,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=None,\n",
      "                       splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81      3770\n",
      "           1       0.55      1.00      0.71      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.78      0.84      0.76      5248\n",
      "weighted avg       0.87      0.77      0.78      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68      1617\n",
      "           1       0.39      0.70      0.51       633\n",
      "\n",
      "    accuracy                           0.61      2250\n",
      "   macro avg       0.61      0.64      0.59      2250\n",
      "weighted avg       0.71      0.61      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               930  687\n",
      "1               187  446\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Params {'n_estimators': 6, 'min_samples_leaf': 13, 'max_depth': 7, 'class_weight': {1: 57.57142857142857}}\n",
      "Best Score 0.7677214580779881\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              class_weight={1: 57.57142857142857}, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=7,\n",
      "              min_child_weight=1, min_samples_leaf=13, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=6, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3770\n",
      "           1       0.93      0.29      0.45      1478\n",
      "\n",
      "    accuracy                           0.79      5248\n",
      "   macro avg       0.85      0.64      0.66      5248\n",
      "weighted avg       0.82      0.79      0.75      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86      1617\n",
      "           1       0.83      0.26      0.40       633\n",
      "\n",
      "    accuracy                           0.78      2250\n",
      "   macro avg       0.80      0.62      0.63      2250\n",
      "weighted avg       0.79      0.78      0.73      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1583   34\n",
      "1                468  165\n",
      "Best Params {'num_leaves': 39, 'n_estimators': 8, 'max_depth': 33, 'class_weight': {1: 87.87755102040815}}\n",
      "Best Score 0.44340351355032004\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={1: 87.87755102040815},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=33, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=8, n_jobs=-1, num_leaves=39,\n",
      "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.26      0.41      3770\n",
      "           1       0.34      1.00      0.51      1478\n",
      "\n",
      "    accuracy                           0.46      5248\n",
      "   macro avg       0.67      0.63      0.46      5248\n",
      "weighted avg       0.82      0.46      0.44      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.26      0.40      1617\n",
      "           1       0.34      0.96      0.50       633\n",
      "\n",
      "    accuracy                           0.46      2250\n",
      "   macro avg       0.64      0.61      0.45      2250\n",
      "weighted avg       0.78      0.46      0.43      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               416  1201\n",
      "1                23   610\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "Best Params {'l2_leaf_reg': 81, 'iterations': 13, 'depth': 4}\n",
      "Best Score 0.44340351355032004\n",
      "0:\tlearn: 0.6863152\ttotal: 3.66ms\tremaining: 43.9ms\n",
      "1:\tlearn: 0.6802230\ttotal: 5.9ms\tremaining: 32.4ms\n",
      "2:\tlearn: 0.6733291\ttotal: 8.11ms\tremaining: 27ms\n",
      "3:\tlearn: 0.6680569\ttotal: 10.5ms\tremaining: 23.6ms\n",
      "4:\tlearn: 0.6620562\ttotal: 12.9ms\tremaining: 20.6ms\n",
      "5:\tlearn: 0.6568023\ttotal: 15.2ms\tremaining: 17.7ms\n",
      "6:\tlearn: 0.6524039\ttotal: 17.5ms\tremaining: 15ms\n",
      "7:\tlearn: 0.6480252\ttotal: 19.9ms\tremaining: 12.5ms\n",
      "8:\tlearn: 0.6428704\ttotal: 22.4ms\tremaining: 9.97ms\n",
      "9:\tlearn: 0.6389692\ttotal: 24.9ms\tremaining: 7.48ms\n",
      "10:\tlearn: 0.6352073\ttotal: 27.4ms\tremaining: 4.98ms\n",
      "11:\tlearn: 0.6306750\ttotal: 29.8ms\tremaining: 2.48ms\n",
      "12:\tlearn: 0.6268239\ttotal: 32.2ms\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2BBF3EC8>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       1.00      0.18      0.31      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.88      0.59      0.59      5248\n",
      "weighted avg       0.83      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       1.00      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.88      0.59      0.59      2250\n",
      "weighted avg       0.83      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1617    0\n",
      "1                513  120\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    " \n",
    "\n",
    "def modeling_ (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "def randomsearch(model,param_grid):\n",
    "    n_iter_search = 20\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=n_iter_search)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    params = random_search.best_params_\n",
    "    print (\"Best Params\", random_search.best_params_)\n",
    "    print (\"Best Score\", random_search.best_score_)\n",
    "    return params\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES] \n",
    "\n",
    "\n",
    "# Разбиваем данные и нормализуем\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "\n",
    "def saving(preds_final,model):\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/RS/{model}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n",
    "\n",
    "model = LogisticRegression()\n",
    "C = np.power(10.0, np.arange(-10, 10))\n",
    "max_iter = np.linspace(1,500)\n",
    "param_grid = {'C': C, 'max_iter': max_iter}\n",
    "model = LogisticRegression(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'LogisticRegression')\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "C = (0.0001,0.001,0.01,0.1,1)#np.power(10.0, np.arange(-10, 10))\n",
    "#     gamma = ['scale','auto']\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "param_grid = {'C': C}#,'kernel':kernel}#,'gamma':gamma}\n",
    "model = SVC(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'SVC')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = np.linspace(1,100,dtype = int)\n",
    "leaf_size = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'n_neighbors': n_neighbors, 'leaf_size': leaf_size}\n",
    "model = KNeighborsClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'KNeighborsClassifier')\n",
    "                  \n",
    "model = DecisionTreeClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight}\n",
    "model = DecisionTreeClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'DecisionTreeClassifier')\n",
    "                  \n",
    "                  \n",
    "model = xgb.XGBClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = xgb.XGBClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'XGBClassifier')\n",
    "                  \n",
    "model = lgbm.LGBMClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "num_leaves = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'num_leaves': num_leaves, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = lgbm.LGBMClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'LGBMClassifier')\n",
    "                  \n",
    "model_catb = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "iterations = np.linspace(1,100,dtype = int)\n",
    "depth = np.linspace(1,16,dtype = int)\n",
    "l2_leaf_reg = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'iterations':iterations,'depth': depth, 'l2_leaf_reg': l2_leaf_reg}      \n",
    "model = catb.CatBoostClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'CatBoostClassifier')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели  с подбором параметров (RandomSearchCV), без масштабирования, с балансировкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'max_iter': 235.22448979591837, 'C': 1e-09}\n",
      "Best Score 0.7675317082028237\n",
      "LogisticRegression(C=1e-09, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=235.22448979591837, multi_class='auto', n_jobs=None,\n",
      "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1478\n",
      "           1       0.64      0.66      0.65      1478\n",
      "\n",
      "    accuracy                           0.64      2956\n",
      "   macro avg       0.64      0.64      0.64      2956\n",
      "weighted avg       0.64      0.64      0.64      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.62      0.70      1617\n",
      "           1       0.39      0.62      0.48       633\n",
      "\n",
      "    accuracy                           0.62      2250\n",
      "   macro avg       0.60      0.62      0.59      2250\n",
      "weighted avg       0.69      0.62      0.64      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1006  611\n",
      "1                243  390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 0.0001}\n",
      "Best Score 0.7183690589677243\n",
      "SVC(C=0.0001, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27      1478\n",
      "           1       0.54      1.00      0.70      1478\n",
      "\n",
      "    accuracy                           0.58      2956\n",
      "   macro avg       0.77      0.58      0.49      2956\n",
      "weighted avg       0.77      0.58      0.49      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29      1617\n",
      "           1       0.32      1.00      0.48       633\n",
      "\n",
      "    accuracy                           0.40      2250\n",
      "   macro avg       0.66      0.58      0.38      2250\n",
      "weighted avg       0.81      0.40      0.34      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               269  1348\n",
      "1                 0   633\n",
      "Best Params {'n_neighbors': 59, 'leaf_size': 71}\n",
      "Best Score 0.7208447047074311\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=71, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=59, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61      1478\n",
      "           1       0.62      0.73      0.67      1478\n",
      "\n",
      "    accuracy                           0.65      2956\n",
      "   macro avg       0.65      0.65      0.64      2956\n",
      "weighted avg       0.65      0.65      0.64      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.52      0.63      1617\n",
      "           1       0.36      0.70      0.48       633\n",
      "\n",
      "    accuracy                           0.57      2250\n",
      "   macro avg       0.59      0.61      0.55      2250\n",
      "weighted avg       0.69      0.57      0.59      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               839  778\n",
      "1               193  440\n",
      "Best Params {'min_samples_leaf': 27, 'max_depth': 49, 'class_weight': {1: 3.020408163265306}}\n",
      "Best Score 0.6114708792954742\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={1: 3.020408163265306},\n",
      "                       criterion='gini', max_depth=49, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=27,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=None,\n",
      "                       splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61      1478\n",
      "           1       0.64      0.95      0.76      1478\n",
      "\n",
      "    accuracy                           0.70      2956\n",
      "   macro avg       0.77      0.70      0.68      2956\n",
      "weighted avg       0.77      0.70      0.68      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.37      0.52      1617\n",
      "           1       0.35      0.88      0.50       633\n",
      "\n",
      "    accuracy                           0.51      2250\n",
      "   macro avg       0.62      0.62      0.51      2250\n",
      "weighted avg       0.74      0.51      0.51      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               591  1026\n",
      "1                75   558\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Params {'n_estimators': 9, 'min_samples_leaf': 67, 'max_depth': 3, 'class_weight': {1: 59.59183673469387}}\n",
      "Best Score 0.7711518452948387\n",
      "[16:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              class_weight={1: 59.59183673469387}, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, min_samples_leaf=67, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=9, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64      1478\n",
      "           1       0.65      0.78      0.71      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.68      0.68      0.67      2956\n",
      "weighted avg       0.68      0.68      0.67      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.56      0.67      1617\n",
      "           1       0.40      0.76      0.52       633\n",
      "\n",
      "    accuracy                           0.61      2250\n",
      "   macro avg       0.63      0.66      0.60      2250\n",
      "weighted avg       0.73      0.61      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               901  716\n",
      "1               154  479\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Best Params {'num_leaves': 67, 'n_estimators': 3, 'max_depth': 47, 'class_weight': {1: 97.97959183673468}}\n",
      "Best Score 0.43597131054519045\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={1: 97.97959183673468},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=47, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=3, n_jobs=-1, num_leaves=67,\n",
      "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.30      1478\n",
      "           1       0.55      1.00      0.71      1478\n",
      "\n",
      "    accuracy                           0.59      2956\n",
      "   macro avg       0.77      0.59      0.51      2956\n",
      "weighted avg       0.77      0.59      0.51      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.18      0.31      1617\n",
      "           1       0.32      0.99      0.49       633\n",
      "\n",
      "    accuracy                           0.41      2250\n",
      "   macro avg       0.65      0.59      0.40      2250\n",
      "weighted avg       0.79      0.41      0.36      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               293  1324\n",
      "1                 6   627\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "Best Params {'l2_leaf_reg': 19, 'iterations': 100, 'depth': 7}\n",
      "Best Score 0.43597131054519045\n",
      "0:\tlearn: 0.6900515\ttotal: 4.69ms\tremaining: 465ms\n",
      "1:\tlearn: 0.6876460\ttotal: 8.91ms\tremaining: 436ms\n",
      "2:\tlearn: 0.6840842\ttotal: 12.9ms\tremaining: 417ms\n",
      "3:\tlearn: 0.6819458\ttotal: 17ms\tremaining: 408ms\n",
      "4:\tlearn: 0.6784213\ttotal: 19.5ms\tremaining: 371ms\n",
      "5:\tlearn: 0.6755069\ttotal: 23.6ms\tremaining: 369ms\n",
      "6:\tlearn: 0.6731848\ttotal: 29.6ms\tremaining: 394ms\n",
      "7:\tlearn: 0.6704501\ttotal: 33.7ms\tremaining: 388ms\n",
      "8:\tlearn: 0.6685506\ttotal: 38ms\tremaining: 384ms\n",
      "9:\tlearn: 0.6666845\ttotal: 42.3ms\tremaining: 381ms\n",
      "10:\tlearn: 0.6642366\ttotal: 46.4ms\tremaining: 375ms\n",
      "11:\tlearn: 0.6622887\ttotal: 50.6ms\tremaining: 371ms\n",
      "12:\tlearn: 0.6601622\ttotal: 54.6ms\tremaining: 366ms\n",
      "13:\tlearn: 0.6582547\ttotal: 58.9ms\tremaining: 362ms\n",
      "14:\tlearn: 0.6565510\ttotal: 63.4ms\tremaining: 359ms\n",
      "15:\tlearn: 0.6544758\ttotal: 67.3ms\tremaining: 353ms\n",
      "16:\tlearn: 0.6530754\ttotal: 71.4ms\tremaining: 349ms\n",
      "17:\tlearn: 0.6511941\ttotal: 75.5ms\tremaining: 344ms\n",
      "18:\tlearn: 0.6493675\ttotal: 79.4ms\tremaining: 338ms\n",
      "19:\tlearn: 0.6477715\ttotal: 83.4ms\tremaining: 334ms\n",
      "20:\tlearn: 0.6457517\ttotal: 89.2ms\tremaining: 335ms\n",
      "21:\tlearn: 0.6439478\ttotal: 90.8ms\tremaining: 322ms\n",
      "22:\tlearn: 0.6425281\ttotal: 94.5ms\tremaining: 316ms\n",
      "23:\tlearn: 0.6408411\ttotal: 97.7ms\tremaining: 310ms\n",
      "24:\tlearn: 0.6394687\ttotal: 101ms\tremaining: 303ms\n",
      "25:\tlearn: 0.6376275\ttotal: 104ms\tremaining: 297ms\n",
      "26:\tlearn: 0.6360563\ttotal: 108ms\tremaining: 292ms\n",
      "27:\tlearn: 0.6345404\ttotal: 111ms\tremaining: 285ms\n",
      "28:\tlearn: 0.6330912\ttotal: 114ms\tremaining: 280ms\n",
      "29:\tlearn: 0.6321188\ttotal: 118ms\tremaining: 275ms\n",
      "30:\tlearn: 0.6309774\ttotal: 121ms\tremaining: 270ms\n",
      "31:\tlearn: 0.6295270\ttotal: 124ms\tremaining: 264ms\n",
      "32:\tlearn: 0.6284781\ttotal: 128ms\tremaining: 259ms\n",
      "33:\tlearn: 0.6266762\ttotal: 131ms\tremaining: 254ms\n",
      "34:\tlearn: 0.6254010\ttotal: 134ms\tremaining: 249ms\n",
      "35:\tlearn: 0.6242199\ttotal: 138ms\tremaining: 245ms\n",
      "36:\tlearn: 0.6229683\ttotal: 141ms\tremaining: 240ms\n",
      "37:\tlearn: 0.6221554\ttotal: 145ms\tremaining: 236ms\n",
      "38:\tlearn: 0.6210280\ttotal: 148ms\tremaining: 231ms\n",
      "39:\tlearn: 0.6200857\ttotal: 152ms\tremaining: 227ms\n",
      "40:\tlearn: 0.6188119\ttotal: 155ms\tremaining: 223ms\n",
      "41:\tlearn: 0.6173822\ttotal: 159ms\tremaining: 219ms\n",
      "42:\tlearn: 0.6161489\ttotal: 162ms\tremaining: 214ms\n",
      "43:\tlearn: 0.6150071\ttotal: 165ms\tremaining: 210ms\n",
      "44:\tlearn: 0.6137527\ttotal: 169ms\tremaining: 206ms\n",
      "45:\tlearn: 0.6128392\ttotal: 172ms\tremaining: 202ms\n",
      "46:\tlearn: 0.6117258\ttotal: 176ms\tremaining: 198ms\n",
      "47:\tlearn: 0.6106188\ttotal: 179ms\tremaining: 194ms\n",
      "48:\tlearn: 0.6097899\ttotal: 183ms\tremaining: 190ms\n",
      "49:\tlearn: 0.6086502\ttotal: 186ms\tremaining: 186ms\n",
      "50:\tlearn: 0.6079116\ttotal: 190ms\tremaining: 182ms\n",
      "51:\tlearn: 0.6069269\ttotal: 193ms\tremaining: 178ms\n",
      "52:\tlearn: 0.6061643\ttotal: 197ms\tremaining: 174ms\n",
      "53:\tlearn: 0.6049851\ttotal: 200ms\tremaining: 170ms\n",
      "54:\tlearn: 0.6042813\ttotal: 203ms\tremaining: 166ms\n",
      "55:\tlearn: 0.6036808\ttotal: 207ms\tremaining: 163ms\n",
      "56:\tlearn: 0.6028052\ttotal: 211ms\tremaining: 159ms\n",
      "57:\tlearn: 0.6021689\ttotal: 215ms\tremaining: 155ms\n",
      "58:\tlearn: 0.6016051\ttotal: 218ms\tremaining: 151ms\n",
      "59:\tlearn: 0.6005906\ttotal: 221ms\tremaining: 147ms\n",
      "60:\tlearn: 0.5999206\ttotal: 225ms\tremaining: 144ms\n",
      "61:\tlearn: 0.5988672\ttotal: 229ms\tremaining: 140ms\n",
      "62:\tlearn: 0.5978508\ttotal: 232ms\tremaining: 136ms\n",
      "63:\tlearn: 0.5970400\ttotal: 236ms\tremaining: 133ms\n",
      "64:\tlearn: 0.5962734\ttotal: 240ms\tremaining: 129ms\n",
      "65:\tlearn: 0.5955889\ttotal: 243ms\tremaining: 125ms\n",
      "66:\tlearn: 0.5948965\ttotal: 247ms\tremaining: 122ms\n",
      "67:\tlearn: 0.5941113\ttotal: 252ms\tremaining: 119ms\n",
      "68:\tlearn: 0.5935077\ttotal: 256ms\tremaining: 115ms\n",
      "69:\tlearn: 0.5927241\ttotal: 259ms\tremaining: 111ms\n",
      "70:\tlearn: 0.5920461\ttotal: 262ms\tremaining: 107ms\n",
      "71:\tlearn: 0.5913693\ttotal: 266ms\tremaining: 103ms\n",
      "72:\tlearn: 0.5908476\ttotal: 270ms\tremaining: 100ms\n",
      "73:\tlearn: 0.5902391\ttotal: 274ms\tremaining: 96.2ms\n",
      "74:\tlearn: 0.5895569\ttotal: 277ms\tremaining: 92.3ms\n",
      "75:\tlearn: 0.5888710\ttotal: 280ms\tremaining: 88.6ms\n",
      "76:\tlearn: 0.5881864\ttotal: 284ms\tremaining: 84.9ms\n",
      "77:\tlearn: 0.5877899\ttotal: 288ms\tremaining: 81.3ms\n",
      "78:\tlearn: 0.5870675\ttotal: 293ms\tremaining: 77.8ms\n",
      "79:\tlearn: 0.5865501\ttotal: 298ms\tremaining: 74.4ms\n",
      "80:\tlearn: 0.5859860\ttotal: 302ms\tremaining: 70.8ms\n",
      "81:\tlearn: 0.5852612\ttotal: 306ms\tremaining: 67.1ms\n",
      "82:\tlearn: 0.5848487\ttotal: 310ms\tremaining: 63.4ms\n",
      "83:\tlearn: 0.5842570\ttotal: 314ms\tremaining: 59.7ms\n",
      "84:\tlearn: 0.5837277\ttotal: 317ms\tremaining: 56ms\n",
      "85:\tlearn: 0.5831361\ttotal: 321ms\tremaining: 52.2ms\n",
      "86:\tlearn: 0.5824077\ttotal: 324ms\tremaining: 48.5ms\n",
      "87:\tlearn: 0.5819350\ttotal: 328ms\tremaining: 44.7ms\n",
      "88:\tlearn: 0.5813683\ttotal: 331ms\tremaining: 40.9ms\n",
      "89:\tlearn: 0.5808995\ttotal: 334ms\tremaining: 37.2ms\n",
      "90:\tlearn: 0.5804139\ttotal: 338ms\tremaining: 33.4ms\n",
      "91:\tlearn: 0.5799185\ttotal: 342ms\tremaining: 29.7ms\n",
      "92:\tlearn: 0.5794778\ttotal: 345ms\tremaining: 26ms\n",
      "93:\tlearn: 0.5790830\ttotal: 349ms\tremaining: 22.3ms\n",
      "94:\tlearn: 0.5786237\ttotal: 352ms\tremaining: 18.5ms\n",
      "95:\tlearn: 0.5782141\ttotal: 356ms\tremaining: 14.8ms\n",
      "96:\tlearn: 0.5778346\ttotal: 359ms\tremaining: 11.1ms\n",
      "97:\tlearn: 0.5774391\ttotal: 363ms\tremaining: 7.4ms\n",
      "98:\tlearn: 0.5769141\ttotal: 366ms\tremaining: 3.7ms\n",
      "99:\tlearn: 0.5764429\ttotal: 370ms\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D26969EC8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67      1478\n",
      "           1       0.67      0.74      0.70      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.69      0.68      0.68      2956\n",
      "weighted avg       0.69      0.68      0.68      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.62      0.71      1617\n",
      "           1       0.42      0.70      0.52       633\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.63      0.66      0.62      2250\n",
      "weighted avg       0.72      0.64      0.66      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1002  615\n",
      "1                193  440\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    " \n",
    "\n",
    "def modeling_ (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "def randomsearch(model,param_grid):\n",
    "    n_iter_search = 20\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=n_iter_search)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    params = random_search.best_params_\n",
    "    print (\"Best Params\", random_search.best_params_)\n",
    "    print (\"Best Score\", random_search.best_score_)\n",
    "    return params\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES] \n",
    "\n",
    "\n",
    "# Разбиваем данные и нормализуем\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "# балансировка\n",
    "df_for_balancing = pd.concat([X_train, y_train], axis=1)\n",
    "df_balanced = balance_df_by_target(df_for_balancing, TARGET_NAME, method='under')\n",
    "df_balanced[TARGET_NAME].value_counts()\n",
    "X_train_balanced = df_balanced.drop(columns=TARGET_NAME)\n",
    "y_train_balanced = df_balanced[TARGET_NAME]\n",
    "\n",
    "def saving(preds_final,model):\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/RS/Bal/{model}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n",
    "\n",
    "model = LogisticRegression()\n",
    "C = np.power(10.0, np.arange(-10, 10))\n",
    "max_iter = np.linspace(1,500)\n",
    "param_grid = {'C': C, 'max_iter': max_iter}\n",
    "model = LogisticRegression(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'LogisticRegression')\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "C = (0.0001,0.001,0.01,0.1,1)#np.power(10.0, np.arange(-10, 10))\n",
    "#     gamma = ['scale','auto']\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "param_grid = {'C': C}#,'kernel':kernel}#,'gamma':gamma}\n",
    "model = SVC(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'SVC')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = np.linspace(1,100,dtype = int)\n",
    "leaf_size = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'n_neighbors': n_neighbors, 'leaf_size': leaf_size}\n",
    "model = KNeighborsClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'KNeighborsClassifier')\n",
    "                  \n",
    "model = DecisionTreeClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight}\n",
    "model = DecisionTreeClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'DecisionTreeClassifier')\n",
    "                  \n",
    "                  \n",
    "model = xgb.XGBClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = xgb.XGBClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'XGBClassifier')\n",
    "                  \n",
    "model = lgbm.LGBMClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "num_leaves = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'num_leaves': num_leaves, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = lgbm.LGBMClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'LGBMClassifier')\n",
    "                  \n",
    "model_catb = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "iterations = np.linspace(1,100,dtype = int)\n",
    "depth = np.linspace(1,16,dtype = int)\n",
    "l2_leaf_reg = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'iterations':iterations,'depth': depth, 'l2_leaf_reg': l2_leaf_reg}      \n",
    "model = catb.CatBoostClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'CatBoostClassifier')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели  с подбором параметров (RandomSearchCV), с масштабированием, с балансировкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'max_iter': 469.44897959183675, 'C': 0.01}\n",
      "Best Score 0.7711518452948387\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=469.44897959183675, multi_class='auto', n_jobs=None,\n",
      "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "                   verbose=0, warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      1478\n",
      "           1       0.65      0.64      0.64      1478\n",
      "\n",
      "    accuracy                           0.65      2956\n",
      "   macro avg       0.65      0.65      0.65      2956\n",
      "weighted avg       0.65      0.65      0.65      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71      1617\n",
      "           1       0.39      0.59      0.47       633\n",
      "\n",
      "    accuracy                           0.63      2250\n",
      "   macro avg       0.59      0.61      0.59      2250\n",
      "weighted avg       0.68      0.63      0.64      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1039  578\n",
      "1                262  371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 1}\n",
      "Best Score 0.7696276726133733\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      1478\n",
      "           1       0.67      0.72      0.69      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.68      0.68      0.68      2956\n",
      "weighted avg       0.68      0.68      0.68      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67      1617\n",
      "           1       0.37      0.65      0.47       633\n",
      "\n",
      "    accuracy                           0.59      2250\n",
      "   macro avg       0.59      0.61      0.57      2250\n",
      "weighted avg       0.69      0.59      0.61      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               919  698\n",
      "1               219  414\n",
      "Best Params {'n_neighbors': 23, 'leaf_size': 87}\n",
      "Best Score 0.7705807798810659\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=87, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=23, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68      1478\n",
      "           1       0.68      0.67      0.68      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.68      0.68      0.68      2956\n",
      "weighted avg       0.68      0.68      0.68      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67      1617\n",
      "           1       0.37      0.62      0.46       633\n",
      "\n",
      "    accuracy                           0.59      2250\n",
      "   macro avg       0.58      0.60      0.57      2250\n",
      "weighted avg       0.68      0.59      0.61      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               942  675\n",
      "1               241  392\n",
      "Best Params {'min_samples_leaf': 11, 'max_depth': 48, 'class_weight': {1: 41.408163265306115}}\n",
      "Best Score 0.5264881746788326\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={1: 41.408163265306115},\n",
      "                       criterion='gini', max_depth=48, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=11,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=None,\n",
      "                       splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.28      0.43      1478\n",
      "           1       0.58      1.00      0.73      1478\n",
      "\n",
      "    accuracy                           0.64      2956\n",
      "   macro avg       0.79      0.64      0.58      2956\n",
      "weighted avg       0.79      0.64      0.58      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.37      1617\n",
      "           1       0.33      0.96      0.49       633\n",
      "\n",
      "    accuracy                           0.43      2250\n",
      "   macro avg       0.63      0.60      0.43      2250\n",
      "weighted avg       0.77      0.43      0.40      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               367  1250\n",
      "1                23   610\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Params {'n_estimators': 3, 'min_samples_leaf': 71, 'max_depth': 2, 'class_weight': {1: 57.57142857142857}}\n",
      "Best Score 0.7711518452948387\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              class_weight={1: 57.57142857142857}, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=2,\n",
      "              min_child_weight=1, min_samples_leaf=71, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=3, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.37      0.51      1478\n",
      "           1       0.59      0.90      0.71      1478\n",
      "\n",
      "    accuracy                           0.64      2956\n",
      "   macro avg       0.69      0.64      0.61      2956\n",
      "weighted avg       0.69      0.64      0.61      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.38      0.53      1617\n",
      "           1       0.36      0.90      0.52       633\n",
      "\n",
      "    accuracy                           0.52      2250\n",
      "   macro avg       0.63      0.64      0.52      2250\n",
      "weighted avg       0.75      0.52      0.53      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0     1\n",
      "Credit Default           \n",
      "0               610  1007\n",
      "1                63   570\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Best Params {'num_leaves': 85, 'n_estimators': 1, 'max_depth': 45, 'class_weight': {1: 1.0}}\n",
      "Best Score 0.7183690589677243\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={1: 1.0},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=45, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=1, n_jobs=-1, num_leaves=85,\n",
      "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      1478\n",
      "           1       0.79      0.74      0.76      1478\n",
      "\n",
      "    accuracy                           0.77      2956\n",
      "   macro avg       0.77      0.77      0.77      2956\n",
      "weighted avg       0.77      0.77      0.77      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.72      1617\n",
      "           1       0.40      0.62      0.49       633\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.61      0.63      0.60      2250\n",
      "weighted avg       0.70      0.64      0.65      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1037  580\n",
      "1                241  392\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "Best Params {'l2_leaf_reg': 45, 'iterations': 35, 'depth': 10}\n",
      "Best Score 0.7183690589677243\n",
      "0:\tlearn: 0.6912721\ttotal: 34ms\tremaining: 1.16s\n",
      "1:\tlearn: 0.6895436\ttotal: 71.6ms\tremaining: 1.18s\n",
      "2:\tlearn: 0.6876989\ttotal: 108ms\tremaining: 1.15s\n",
      "3:\tlearn: 0.6863703\ttotal: 136ms\tremaining: 1.05s\n",
      "4:\tlearn: 0.6850192\ttotal: 172ms\tremaining: 1.03s\n",
      "5:\tlearn: 0.6829247\ttotal: 206ms\tremaining: 996ms\n",
      "6:\tlearn: 0.6814719\ttotal: 237ms\tremaining: 949ms\n",
      "7:\tlearn: 0.6804660\ttotal: 267ms\tremaining: 900ms\n",
      "8:\tlearn: 0.6792332\ttotal: 295ms\tremaining: 854ms\n",
      "9:\tlearn: 0.6778203\ttotal: 325ms\tremaining: 811ms\n",
      "10:\tlearn: 0.6771835\ttotal: 355ms\tremaining: 775ms\n",
      "11:\tlearn: 0.6759758\ttotal: 389ms\tremaining: 745ms\n",
      "12:\tlearn: 0.6745734\ttotal: 425ms\tremaining: 720ms\n",
      "13:\tlearn: 0.6733605\ttotal: 457ms\tremaining: 685ms\n",
      "14:\tlearn: 0.6720860\ttotal: 488ms\tremaining: 651ms\n",
      "15:\tlearn: 0.6700626\ttotal: 497ms\tremaining: 590ms\n",
      "16:\tlearn: 0.6690341\ttotal: 535ms\tremaining: 567ms\n",
      "17:\tlearn: 0.6672473\ttotal: 565ms\tremaining: 534ms\n",
      "18:\tlearn: 0.6666474\ttotal: 596ms\tremaining: 502ms\n",
      "19:\tlearn: 0.6654120\ttotal: 628ms\tremaining: 471ms\n",
      "20:\tlearn: 0.6637225\ttotal: 637ms\tremaining: 425ms\n",
      "21:\tlearn: 0.6628071\ttotal: 672ms\tremaining: 397ms\n",
      "22:\tlearn: 0.6618719\ttotal: 703ms\tremaining: 367ms\n",
      "23:\tlearn: 0.6606294\ttotal: 730ms\tremaining: 334ms\n",
      "24:\tlearn: 0.6591846\ttotal: 767ms\tremaining: 307ms\n",
      "25:\tlearn: 0.6582377\ttotal: 806ms\tremaining: 279ms\n",
      "26:\tlearn: 0.6569859\ttotal: 814ms\tremaining: 241ms\n",
      "27:\tlearn: 0.6561690\ttotal: 818ms\tremaining: 205ms\n",
      "28:\tlearn: 0.6553947\ttotal: 848ms\tremaining: 175ms\n",
      "29:\tlearn: 0.6543006\ttotal: 887ms\tremaining: 148ms\n",
      "30:\tlearn: 0.6535286\ttotal: 916ms\tremaining: 118ms\n",
      "31:\tlearn: 0.6528644\ttotal: 949ms\tremaining: 89ms\n",
      "32:\tlearn: 0.6522220\ttotal: 978ms\tremaining: 59.2ms\n",
      "33:\tlearn: 0.6507937\ttotal: 1s\tremaining: 29.5ms\n",
      "34:\tlearn: 0.6501617\ttotal: 1.04s\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D206F9448>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65      1478\n",
      "           1       0.65      0.75      0.70      1478\n",
      "\n",
      "    accuracy                           0.68      2956\n",
      "   macro avg       0.68      0.68      0.67      2956\n",
      "weighted avg       0.68      0.68      0.67      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.68      1617\n",
      "           1       0.39      0.70      0.50       633\n",
      "\n",
      "    accuracy                           0.61      2250\n",
      "   macro avg       0.61      0.64      0.59      2250\n",
      "weighted avg       0.71      0.61      0.63      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               930  687\n",
      "1               189  444\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    " \n",
    "\n",
    "def modeling_ (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "def randomsearch(model,param_grid):\n",
    "    n_iter_search = 20\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=n_iter_search)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    params = random_search.best_params_\n",
    "    print (\"Best Params\", random_search.best_params_)\n",
    "    print (\"Best Score\", random_search.best_score_)\n",
    "    return params\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES] \n",
    "\n",
    "\n",
    "# Масштабируем данные\n",
    "scaler = StandardScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "df = df_norm.copy()\n",
    "\n",
    "# Разбиваем данные и нормализуем\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# балансировка\n",
    "df_for_balancing = pd.concat([X_train, y_train], axis=1)\n",
    "df_balanced = balance_df_by_target(df_for_balancing, TARGET_NAME, method='under')\n",
    "df_balanced[TARGET_NAME].value_counts()\n",
    "X_train_balanced = df_balanced.drop(columns=TARGET_NAME)\n",
    "y_train_balanced = df_balanced[TARGET_NAME]\n",
    "\n",
    "\n",
    "def saving(preds_final,model):\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/RS/Scal/Bal/{model}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n",
    "\n",
    "model = LogisticRegression()\n",
    "C = np.power(10.0, np.arange(-10, 10))\n",
    "max_iter = np.linspace(1,500)\n",
    "param_grid = {'C': C, 'max_iter': max_iter}\n",
    "model = LogisticRegression(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'LogisticRegression')\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "C = (0.0001,0.001,0.01,0.1,1)#np.power(10.0, np.arange(-10, 10))\n",
    "#     gamma = ['scale','auto']\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "param_grid = {'C': C}#,'kernel':kernel}#,'gamma':gamma}\n",
    "model = SVC(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'SVC')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = np.linspace(1,100,dtype = int)\n",
    "leaf_size = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'n_neighbors': n_neighbors, 'leaf_size': leaf_size}\n",
    "model = KNeighborsClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'KNeighborsClassifier')\n",
    "                  \n",
    "model = DecisionTreeClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight}\n",
    "model = DecisionTreeClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'DecisionTreeClassifier')\n",
    "                  \n",
    "                  \n",
    "model = xgb.XGBClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = xgb.XGBClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'XGBClassifier')\n",
    "                  \n",
    "model = lgbm.LGBMClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "num_leaves = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'num_leaves': num_leaves, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = lgbm.LGBMClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'LGBMClassifier')\n",
    "                  \n",
    "model_catb = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "iterations = np.linspace(1,100,dtype = int)\n",
    "depth = np.linspace(1,16,dtype = int)\n",
    "l2_leaf_reg = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'iterations':iterations,'depth': depth, 'l2_leaf_reg': l2_leaf_reg}      \n",
    "model = catb.CatBoostClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train_balanced, X_test, y_train_balanced, y_test)\n",
    "saving(preds_final,'CatBoostClassifier')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все модели  с подбором параметров (RandomSearchCV), с масштабированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'max_iter': 1.0, 'C': 10.0}\n",
      "Best Score 0.7713430478006266\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1.0,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       0.98      0.19      0.32      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.87      0.60      0.59      5248\n",
      "weighted avg       0.82      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       0.98      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.87      0.60      0.59      2250\n",
      "weighted avg       0.82      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1614    3\n",
      "1                510  123\n",
      "Best Params {'C': 1}\n",
      "Best Score 0.7696276726133733\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       1.00      0.20      0.34      1478\n",
      "\n",
      "    accuracy                           0.78      5248\n",
      "   macro avg       0.88      0.60      0.60      5248\n",
      "weighted avg       0.83      0.78      0.72      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       0.98      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.87      0.60      0.59      2250\n",
      "weighted avg       0.82      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1614    3\n",
      "1                510  123\n",
      "Best Params {'n_neighbors': 43, 'leaf_size': 57}\n",
      "Best Score 0.7705804167234102\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=57, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=43, p=2,\n",
      "                     weights='uniform')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       0.99      0.19      0.32      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.87      0.59      0.59      5248\n",
      "weighted avg       0.82      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       0.98      0.19      0.32       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.87      0.60      0.59      2250\n",
      "weighted avg       0.82      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1615    2\n",
      "1                511  122\n",
      "Best Params {'min_samples_leaf': 3, 'max_depth': 28, 'class_weight': {1: 7.061224489795918}}\n",
      "Best Score 0.6362358708974535\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight={1: 7.061224489795918},\n",
      "                       criterion='gini', max_depth=28, max_features=None,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=3,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       presort='deprecated', random_state=None,\n",
      "                       splitter='best')\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89      3770\n",
      "           1       0.66      1.00      0.80      1478\n",
      "\n",
      "    accuracy                           0.86      5248\n",
      "   macro avg       0.83      0.90      0.84      5248\n",
      "weighted avg       0.91      0.86      0.86      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71      1617\n",
      "           1       0.39      0.58      0.46       633\n",
      "\n",
      "    accuracy                           0.62      2250\n",
      "   macro avg       0.59      0.61      0.59      2250\n",
      "weighted avg       0.68      0.62      0.64      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1039  578\n",
      "1                269  364\n",
      "[16:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Params {'n_estimators': 3, 'min_samples_leaf': 79, 'max_depth': 4, 'class_weight': {1: 79.79591836734693}}\n",
      "Best Score 0.7711518452948387\n",
      "[16:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { class_weight, min_samples_leaf } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "              class_weight={1: 79.79591836734693}, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=1, min_samples_leaf=79, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=3, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       1.00      0.19      0.32      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.88      0.59      0.59      5248\n",
      "weighted avg       0.83      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       1.00      0.19      0.33       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.88      0.60      0.59      2250\n",
      "weighted avg       0.83      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1617    0\n",
      "1                510  123\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Best Params {'num_leaves': 89, 'n_estimators': 2, 'max_depth': 20, 'class_weight': {1: 3.020408163265306}}\n",
      "Best Score 0.5287735258068909\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight={1: 3.020408163265306},\n",
      "               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
      "               max_depth=20, min_child_samples=20, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=2, n_jobs=-1, num_leaves=89,\n",
      "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
      "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "               subsample_freq=0)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.47      0.63      3770\n",
      "           1       0.41      0.96      0.58      1478\n",
      "\n",
      "    accuracy                           0.61      5248\n",
      "   macro avg       0.69      0.71      0.61      5248\n",
      "weighted avg       0.81      0.61      0.62      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.41      0.56      1617\n",
      "           1       0.36      0.84      0.50       633\n",
      "\n",
      "    accuracy                           0.53      2250\n",
      "   macro avg       0.61      0.62      0.53      2250\n",
      "weighted avg       0.72      0.53      0.54      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0             0    1\n",
      "Credit Default          \n",
      "0               666  951\n",
      "1               103  530\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] Unknown parameter: l2_leaf_reg\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "Best Params {'l2_leaf_reg': 23, 'iterations': 67, 'depth': 12}\n",
      "Best Score 0.5287735258068909\n",
      "0:\tlearn: 0.6858688\ttotal: 28.1ms\tremaining: 1.86s\n",
      "1:\tlearn: 0.6802319\ttotal: 132ms\tremaining: 4.29s\n",
      "2:\tlearn: 0.6753741\ttotal: 229ms\tremaining: 4.89s\n",
      "3:\tlearn: 0.6704579\ttotal: 334ms\tremaining: 5.26s\n",
      "4:\tlearn: 0.6662395\ttotal: 437ms\tremaining: 5.41s\n",
      "5:\tlearn: 0.6617369\ttotal: 558ms\tremaining: 5.67s\n",
      "6:\tlearn: 0.6576134\ttotal: 693ms\tremaining: 5.94s\n",
      "7:\tlearn: 0.6533200\ttotal: 814ms\tremaining: 6s\n",
      "8:\tlearn: 0.6491731\ttotal: 961ms\tremaining: 6.2s\n",
      "9:\tlearn: 0.6443158\ttotal: 1.02s\tremaining: 5.81s\n",
      "10:\tlearn: 0.6381370\ttotal: 1.02s\tremaining: 5.21s\n",
      "11:\tlearn: 0.6337337\ttotal: 1.08s\tremaining: 4.95s\n",
      "12:\tlearn: 0.6293571\ttotal: 1.19s\tremaining: 4.96s\n",
      "13:\tlearn: 0.6263795\ttotal: 1.3s\tremaining: 4.93s\n",
      "14:\tlearn: 0.6231759\ttotal: 1.43s\tremaining: 4.95s\n",
      "15:\tlearn: 0.6190390\ttotal: 1.55s\tremaining: 4.96s\n",
      "16:\tlearn: 0.6142503\ttotal: 1.56s\tremaining: 4.59s\n",
      "17:\tlearn: 0.6119392\ttotal: 1.69s\tremaining: 4.59s\n",
      "18:\tlearn: 0.6084193\ttotal: 1.82s\tremaining: 4.59s\n",
      "19:\tlearn: 0.6042957\ttotal: 1.83s\tremaining: 4.31s\n",
      "20:\tlearn: 0.6006394\ttotal: 1.96s\tremaining: 4.29s\n",
      "21:\tlearn: 0.5977673\ttotal: 2.1s\tremaining: 4.29s\n",
      "22:\tlearn: 0.5959005\ttotal: 2.22s\tremaining: 4.25s\n",
      "23:\tlearn: 0.5931302\ttotal: 2.23s\tremaining: 4s\n",
      "24:\tlearn: 0.5903256\ttotal: 2.36s\tremaining: 3.96s\n",
      "25:\tlearn: 0.5879548\ttotal: 2.48s\tremaining: 3.91s\n",
      "26:\tlearn: 0.5850772\ttotal: 2.63s\tremaining: 3.9s\n",
      "27:\tlearn: 0.5828056\ttotal: 2.76s\tremaining: 3.84s\n",
      "28:\tlearn: 0.5805207\ttotal: 2.89s\tremaining: 3.79s\n",
      "29:\tlearn: 0.5778760\ttotal: 3s\tremaining: 3.7s\n",
      "30:\tlearn: 0.5754411\ttotal: 3.1s\tremaining: 3.6s\n",
      "31:\tlearn: 0.5733310\ttotal: 3.21s\tremaining: 3.51s\n",
      "32:\tlearn: 0.5718016\ttotal: 3.3s\tremaining: 3.4s\n",
      "33:\tlearn: 0.5700760\ttotal: 3.41s\tremaining: 3.31s\n",
      "34:\tlearn: 0.5680778\ttotal: 3.53s\tremaining: 3.23s\n",
      "35:\tlearn: 0.5660059\ttotal: 3.63s\tremaining: 3.13s\n",
      "36:\tlearn: 0.5646696\ttotal: 3.75s\tremaining: 3.04s\n",
      "37:\tlearn: 0.5631310\ttotal: 3.77s\tremaining: 2.87s\n",
      "38:\tlearn: 0.5609923\ttotal: 3.77s\tremaining: 2.71s\n",
      "39:\tlearn: 0.5593749\ttotal: 3.88s\tremaining: 2.62s\n",
      "40:\tlearn: 0.5580404\ttotal: 3.98s\tremaining: 2.52s\n",
      "41:\tlearn: 0.5558383\ttotal: 4.08s\tremaining: 2.43s\n",
      "42:\tlearn: 0.5546747\ttotal: 4.18s\tremaining: 2.34s\n",
      "43:\tlearn: 0.5532157\ttotal: 4.28s\tremaining: 2.24s\n",
      "44:\tlearn: 0.5518435\ttotal: 4.38s\tremaining: 2.14s\n",
      "45:\tlearn: 0.5506005\ttotal: 4.49s\tremaining: 2.05s\n",
      "46:\tlearn: 0.5491039\ttotal: 4.52s\tremaining: 1.92s\n",
      "47:\tlearn: 0.5478377\ttotal: 4.64s\tremaining: 1.84s\n",
      "48:\tlearn: 0.5465810\ttotal: 4.77s\tremaining: 1.75s\n",
      "49:\tlearn: 0.5453691\ttotal: 4.87s\tremaining: 1.65s\n",
      "50:\tlearn: 0.5437819\ttotal: 4.97s\tremaining: 1.56s\n",
      "51:\tlearn: 0.5427556\ttotal: 5.09s\tremaining: 1.47s\n",
      "52:\tlearn: 0.5414731\ttotal: 5.19s\tremaining: 1.37s\n",
      "53:\tlearn: 0.5394990\ttotal: 5.2s\tremaining: 1.25s\n",
      "54:\tlearn: 0.5386995\ttotal: 5.29s\tremaining: 1.16s\n",
      "55:\tlearn: 0.5375350\ttotal: 5.41s\tremaining: 1.06s\n",
      "56:\tlearn: 0.5364517\ttotal: 5.52s\tremaining: 969ms\n",
      "57:\tlearn: 0.5355221\ttotal: 5.64s\tremaining: 875ms\n",
      "58:\tlearn: 0.5342168\ttotal: 5.65s\tremaining: 766ms\n",
      "59:\tlearn: 0.5335022\ttotal: 5.76s\tremaining: 672ms\n",
      "60:\tlearn: 0.5325886\ttotal: 5.88s\tremaining: 579ms\n",
      "61:\tlearn: 0.5319413\ttotal: 6s\tremaining: 484ms\n",
      "62:\tlearn: 0.5310664\ttotal: 6.05s\tremaining: 384ms\n",
      "63:\tlearn: 0.5303940\ttotal: 6.16s\tremaining: 289ms\n",
      "64:\tlearn: 0.5295157\ttotal: 6.26s\tremaining: 193ms\n",
      "65:\tlearn: 0.5284730\ttotal: 6.37s\tremaining: 96.6ms\n",
      "66:\tlearn: 0.5274719\ttotal: 6.48s\tremaining: 0us\n",
      "<catboost.core.CatBoostClassifier object at 0x0000020D2BBA39C8>\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      3770\n",
      "           1       1.00      0.18      0.31      1478\n",
      "\n",
      "    accuracy                           0.77      5248\n",
      "   macro avg       0.88      0.59      0.58      5248\n",
      "weighted avg       0.83      0.77      0.71      5248\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      1617\n",
      "           1       1.00      0.18      0.31       633\n",
      "\n",
      "    accuracy                           0.77      2250\n",
      "   macro avg       0.88      0.59      0.58      2250\n",
      "weighted avg       0.83      0.77      0.71      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1617    0\n",
      "1                518  115\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df = df_train.copy()\n",
    "df = cleaning(df_train)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test = cleaning(df_test)\n",
    " \n",
    "\n",
    "def modeling_ (model,X_train, X_test, y_train, y_test):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    y_pred_final = model.predict(df_test)\n",
    "    return y_pred_final\n",
    "\n",
    "def randomsearch(model,param_grid):\n",
    "    n_iter_search = 20\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid,n_iter=n_iter_search)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    params = random_search.best_params_\n",
    "    print (\"Best Params\", random_search.best_params_)\n",
    "    print (\"Best Score\", random_search.best_score_)\n",
    "    return params\n",
    "\n",
    "# Отбор признаков\n",
    "NUM_FEATURE_NAMES = ['Annual Income','Tax Liens', 'Number of Open Accounts', 'Years of Credit History',\n",
    "                         'Maximum Open Credit', 'Number of Credit Problems', 'Months since last delinquent',\n",
    "                         'Bankruptcies', 'Current Loan Amount', 'Current Credit Balance', 'Monthly Debt','Credit Score']\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "\n",
    "preds_final = pd.DataFrame()\n",
    "preds_final['Id'] = df_test['Id'].copy()\n",
    "df_test = df_test[NUM_FEATURE_NAMES] \n",
    "\n",
    "\n",
    "# Масштабируем данные\n",
    "scaler = StandardScaler()\n",
    "df_norm = df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "df = df_norm.copy()\n",
    "\n",
    "# Разбиваем данные и нормализуем\n",
    "X = df[NUM_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=21,\n",
    "                                                    stratify=y)\n",
    "\n",
    "def saving(preds_final,model):\n",
    "    output_file = 'submission.csv'\n",
    "    output_dir = Path(MODELS_PATH/f'Func/RS/Scal/{model}')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_final.to_csv((output_dir / output_file), index=False)\n",
    "\n",
    "model = LogisticRegression()\n",
    "C = np.power(10.0, np.arange(-10, 10))\n",
    "max_iter = np.linspace(1,500)\n",
    "param_grid = {'C': C, 'max_iter': max_iter}\n",
    "model = LogisticRegression(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'LogisticRegression')\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "C = (0.0001,0.001,0.01,0.1,1)#np.power(10.0, np.arange(-10, 10))\n",
    "#     gamma = ['scale','auto']\n",
    "# kernel = ['poly', 'rbf', 'sigmoid']\n",
    "param_grid = {'C': C}#,'kernel':kernel}#,'gamma':gamma}\n",
    "model = SVC(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'SVC')\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = np.linspace(1,100,dtype = int)\n",
    "leaf_size = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'n_neighbors': n_neighbors, 'leaf_size': leaf_size}\n",
    "model = KNeighborsClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'KNeighborsClassifier')\n",
    "                  \n",
    "model = DecisionTreeClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight}\n",
    "model = DecisionTreeClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'DecisionTreeClassifier')\n",
    "                  \n",
    "                  \n",
    "model = xgb.XGBClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "min_samples_leaf = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = xgb.XGBClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'XGBClassifier')\n",
    "                  \n",
    "model = lgbm.LGBMClassifier(random_state = 21)\n",
    "max_depth = np.linspace(1,50,dtype = int)\n",
    "num_leaves = np.linspace(1,100,dtype = int)\n",
    "class_weight = [{1: w} for w in np.linspace(1,100)]\n",
    "n_estimators = np.logspace(0,1,dtype = int)                          \n",
    "param_grid = {'max_depth': max_depth, 'num_leaves': num_leaves, 'class_weight':class_weight,\n",
    "              'n_estimators':n_estimators}\n",
    "model = lgbm.LGBMClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'LGBMClassifier')\n",
    "                  \n",
    "model_catb = catb.CatBoostClassifier(silent = True, random_state = 21)\n",
    "iterations = np.linspace(1,100,dtype = int)\n",
    "depth = np.linspace(1,16,dtype = int)\n",
    "l2_leaf_reg = np.linspace(1,100,dtype = int)\n",
    "param_grid = {'iterations':iterations,'depth': depth, 'l2_leaf_reg': l2_leaf_reg}      \n",
    "model = catb.CatBoostClassifier(**randomsearch(model,param_grid))\n",
    "preds_final[TARGET_NAME] = modeling_(model,X_train, X_test, y_train, y_test)\n",
    "saving(preds_final,'CatBoostClassifier')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с выбросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[NUM_FEATURE_NAMES].hist(figsize=(16, 16), bins=20, grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для уделения выбросов в признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_outlier(df, col, threshold):\n",
    "#     # можно по threshold отсекать, а можно и по квантилям\n",
    "#     df.loc[df[col] > threshold, col] = np.nan\n",
    "#     return df\n",
    "\n",
    "# feature_name = 'Current Loan Amount'\n",
    "# df_copy = preprocess_outlier(df_train, feature_name, threshold=9999999)\n",
    "# df_test_copy = preprocess_outlier(df_test, feature_name, threshold=9999999)\n",
    "\n",
    "# df_copy[feature_name].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для определения размера выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gruw5ZHRaFK-"
   },
   "outputs": [],
   "source": [
    "def show_learning_curve_plot(estimator, X, y, cv=3, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, \n",
    "                                                            cv=cv, \n",
    "                                                            scoring='f1',\n",
    "                                                            train_sizes=train_sizes, \n",
    "                                                            n_jobs=n_jobs)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.title(f\"Learning curves ({type(estimator).__name__})\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")     \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_learning_curve_plot(model_knn, X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция выбора порога вероятности для определения класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_proba_calibration_plots(y_predicted_probs, y_true_labels):\n",
    "    preds_with_true_labels = np.array(list(zip(y_predicted_probs, y_true_labels)))\n",
    "\n",
    "    thresholds = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for threshold in np.linspace(0.1, 0.9, 9):\n",
    "        thresholds.append(threshold)\n",
    "        precisions.append(precision_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        recalls.append(recall_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "        f1_scores.append(f1_score(y_true_labels, list(map(int, y_predicted_probs > threshold))))\n",
    "\n",
    "    scores_table = pd.DataFrame({'f1':f1_scores,\n",
    "                                 'precision':precisions,\n",
    "                                 'recall':recalls,\n",
    "                                 'probability':thresholds}).sort_values('f1', ascending=False).round(3)\n",
    "  \n",
    "    figure = plt.figure(figsize = (15, 5))\n",
    "\n",
    "    plt1 = figure.add_subplot(121)\n",
    "    plt1.plot(thresholds, precisions, label='Precision', linewidth=4)\n",
    "    plt1.plot(thresholds, recalls, label='Recall', linewidth=4)\n",
    "    plt1.plot(thresholds, f1_scores, label='F1', linewidth=4)\n",
    "    plt1.set_ylabel('Scores')\n",
    "    plt1.set_xlabel('Probability threshold')\n",
    "    plt1.set_title('Probabilities threshold calibration')\n",
    "    plt1.legend(bbox_to_anchor=(0.25, 0.25))   \n",
    "    plt1.table(cellText = scores_table.values,\n",
    "               colLabels = scores_table.columns, \n",
    "               colLoc = 'center', cellLoc = 'center', loc = 'bottom', bbox = [0, -1.3, 1, 1])\n",
    "\n",
    "    plt2 = figure.add_subplot(122)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 0][:, 0], \n",
    "              label='Another class', color='royalblue', alpha=1)\n",
    "    plt2.hist(preds_with_true_labels[preds_with_true_labels[:, 1] == 1][:, 0], \n",
    "              label='Main class', color='darkcyan', alpha=0.8)\n",
    "    plt2.set_ylabel('Number of examples')\n",
    "    plt2.set_xlabel('Probabilities')\n",
    "    plt2.set_title('Probability histogram')\n",
    "    plt2.legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=1,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69      1478\n",
      "           1       0.69      0.72      0.70      1478\n",
      "\n",
      "    accuracy                           0.70      2956\n",
      "   macro avg       0.70      0.70      0.70      2956\n",
      "weighted avg       0.70      0.70      0.70      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      1617\n",
      "           1       0.42      0.67      0.51       633\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.62      0.65      0.62      2250\n",
      "weighted avg       0.71      0.64      0.66      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1028  589\n",
      "1                211  422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier(random_state=21, \n",
    "                              max_depth=1, \n",
    "                              reg_lambda=10\n",
    "                             )\n",
    "model_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "evaluate_preds(model_xgb, X_train_balanced, X_test, y_train_balanced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4630714 , 0.5369286 ],\n",
       "       [0.524456  , 0.47554398],\n",
       "       [0.6524013 , 0.34759864],\n",
       "       ...,\n",
       "       [0.9741811 , 0.0258189 ],\n",
       "       [0.41566932, 0.5843307 ],\n",
       "       [0.01982021, 0.9801798 ]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_probs = model_xgb.predict_proba(X_test)\n",
    "y_test_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_proba_calibration_plots(y_test_pred_probs[:, 1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для определения важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5VzLQcWvaFLB"
   },
   "outputs": [],
   "source": [
    "def show_feature_importances(feature_names, feature_importances, get_top=None):\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "    feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "       \n",
    "    plt.figure(figsize = (20, len(feature_importances) * 0.355))\n",
    "    \n",
    "    sns.barplot(feature_importances['importance'], feature_importances['feature'])\n",
    "    \n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Importance of features')\n",
    "    plt.show()\n",
    "    \n",
    "    if get_top is not None:\n",
    "        return feature_importances['feature'][:get_top].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQ8AAAEkCAYAAACBncdJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde9xnY73/8dfbUMgwTikVk2MhTQzlkCgd9u5EaRdSqp0Ou1R707brtzXpRGq3K5WmEklJREIlORQVZhjDEBJtSjuSHHIIn98f67p3X3ff+ziH+x7zej4e38e91rWudV2fteYfPo/Pta5UFZIkSZIkSZI02HITHYAkSZIkSZKkycnkoSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJk0CSTZNcmuTOJPv3ub5Okp+065+ciBglSdKyx+ShJEmSFokkNyTZdaLjAEhybpJ/nug4xui9wLlVNbWqPtPn+n7ArcCqVfVvCzNRkqOTfHhhxpAkScsGk4eSJEl6xEhnaf1v3PWBBSNcv7KqagnFM6Qky090DJIkaclYWv/DSpIkSZNYkn2TXJDkU0luT/LrJNu39huT/CHJ63v6H53kyCQ/astyz0uyfs/17ZNcnOTP7e/2PdfOTfKRJBcAfwGOBZ4NHJHkriRHtH6fbnPfkWRukmf3jDEryQlJvtbmX5BkZs/1JyX5TpJbkvxxYMx27Y1JrkrypyQ/7I27z3t5WRv79hb3U1v72cAuPTFvMui+o4HXA+9t13dNslySg5Jc12I6IckaPfd8O8nv2zv7SZLNW/t+wN49Y32vtVeSjQb9m3y4He+c5KYk/57k98BXW/tLksxrz/OzJFv23P/vSX7b3ufVSZ431HuRJEmTl8lDSZIkLS7PBOYDawLfAI4HtgE2Al5Llyhbpaf/3sCHgLWAecBxAC0hdjrwmTbWfwGnJ1mz59596Jb1TgX2BX4KvKOqVqmqd7Q+FwMzgDVaPN9OsmLPGC9rMU4DTgUGko5TgNOA3wDTgSe0fiTZDXgf8Apg7TbvN/u9jJYQ/Cbw7tb3DOB7SR5VVc8dFPM1vfdW1b7tfXy8XT8L2B/YDXgOsC7wJ+BzPbd9H9gYeCxwycD7rKrZg8Z6ab94+3gc3btbH9gvyVbAUcBb6P5dvgicmuTRSTYF3gFsU1VTgRcCN4xyHkmSNImYPJQkSdLicn1VfbWqHgS+BTwJOKSq7quqM4H76RKJA06vqp9U1X3A+4HtkjwJeDFwbVUdW1UPVNU3gV8CvUmvo6tqQbv+137BVNXXq+qPrc8ngUcDm/Z0Ob+qzmjxHgs8vbVvS5ecO7Cq7q6qe6vq/HbtLcDHquqqqnoA+CgwY4jqw1e3Z/xRi/ETwErA9n36jsZbgPdX1U3tnc0C9hhYUlxVR1XVnT3Xnp5ktXHOBfAQ8IH273cP8Gbgi1V1YVU9WFXHAPcBzwIepHu/myVZoapuqKrrFmJuSZI0QUweSpIkaXH5357jewCqanBbb+XhjQMHVXUXcBtd0m5duqq/Xr+hqwD8u3uHkuTf2vLiPye5HViNrspxwO97jv8CrNgScU8CftOSg4OtD3y6Ldu9vcWcQbENeNhzVNVDLe5+fUdjfeDknrmvokvarZNkSpJD25LmO/hb1d9aQ4w1GrdU1b2D5v+3gflbDE8C1q2qX9FVWM4C/pDk+CTrLsTckiRpgpg8lCRJ0mTxpIGDtpx5DeB37Te4km894Lc954M3EXnYefu+4b8D/wSsXlXTgD/TJfpGciOw3hCbhNwIvKWqpvX8Vqqqn/Xp+7DnSBK6Z/5tn76jcSPwD4PmXrGqfgvsBbwc2JUuSTp9YNr2t9+mK38BVu45f9yg64PvuRH4yKD5V26VoVTVN6pqR7pnLuCw8T2mJEmaSCYPJUmSNFn8Y5IdkzyK7tuHF1bVjXTfBtwkyV5Jlk/yamAzuu8QDuV/gQ16zqcCDwC3AMsnORhYdZRxXQTcDBya5DFJVkyyQ7t2JPAfPZuRrJbkVUOMcwLw4iTPS7IC8G90y3z7JRpH40jgIwNLpJOsneTl7drUNvYf6RKCHx107+D3A913JvdqVYsvovuW4nC+BLw1yTPTeUySFyeZmmTTJM9N8mjgXroq0wfH+ZySJGkCmTyUJEnSZPEN4AN0S3+3pttAhar6I/ASumTbH4H3Ai+pqluHGevTdN//+1OSzwA/pNtA5Bq6pcP3Moqlzm3+B+m+r7gR8D/ATXTfL6SqTqarqDu+LQ++AviHIca5mm6jmM8Ct7YxX1pV948mjiGe8VTgzCR3Ar+g26QG4Gt0z/lb4Mp2rddX6L5HeHuSU1rbu1pMt9O9+1MYRlXNofvu4RF0m7X8im6zGui+d3go3XP+nm7TlveN5yElSdLESlW/FQuSJEnSkpPkaOCmqvp/Ex2LJEmS/sbKQ0mSJEmSJEl9mTyUJEmSJEmS1JfLliVJkiRJkiT1ZeWhJEmSJEmSpL6Wn+gApLFYa621avr06RMdhiRJkiRJ0iPG3Llzb62qtftdM3mopcr06dOZM2fORIchSZIkSZL0iJHkN0NdM3mopcoDt9zGLV/4+kSHIUmSJEmSllFrv+21Ex3CEuU3DyVJkiRJkiT1ZfJQkiRJkiRJUl8mDyVJkiRJkiT1ZfJQkiRJkiRJUl8mD5cCSR6X5Pgk1yW5MskZSTZZiPH2TXJEO35rktf1tK87xD3PSnJhknlJrkoya7zzS5IkSZIkaengbsuTXJIAJwPHVNVrWtsMYB3gmp5+U6rqwbGOX1VH9pzuC1wB/K5P12OAf6qqy5JMATYd61yDjTdmSZIkSZIkLRlWHk5+uwB/7U3yVdW8qvppkp2TnJPkG8DlAElem+SiViH4xZboI8kbklyT5Dxgh4GxksxKckCSPYCZwHHt3pUGxfFY4OY2/4NVdWW7f5UkX01yeZL5SV7Z2vdsbVckOaxnvruSHJLkQmC7JFsnOS/J3CQ/TPL4Rf8KJUmSJEmSNB4mDye/LYC5w1zfFnh/VW2W5KnAq4EdqmoG8CCwd0vIfZAuafh8YLPBg1TVicAcYO+qmlFV9wzq8ing6iQnJ3lLkhVb+38Cf66qp1XVlsDZbenzYcBzgRnANkl2a/0fA1xRVc8ELgQ+C+xRVVsDRwEfGRxbkv2SzEky54933THsy5IkSZIkSdKi47Llpd9FVXV9O34esDVwcbfamZWAPwDPBM6tqlsAknwLGNM3E6vqkCTHAS8A9gL2BHYGdgVe09PvT0l2GjTfccBOwCl0Cc2TWvdN6ZKjP2rxTqFVNw6aezYwG2DG+hvUWOKWJEmSJEnS+Jk8nPwWAHsMc/3unuPQfRvxP3o7tKq/hU66VdV1wBeSfAm4Jcmabc7BY2eYYe7t+c5hgAVVtd3CxiZJkiRJkqRFz2XLk9/ZwKOTvHmgIck2SZ7Tp++PgT2SPLb1WyPJ+nTLg3dOsmaSFYBXDTHXncDUfheSvLht3gKwMV0F4e3AmcA7evqt3uZ7TpK12jcX9wTO6zPs1cDaSbZr966QZPMhYpMkSZIkSdISZvJwkquqAnYHnp/kuiQLgFn02RG5bWLy/4Azk8wHfgQ8vqpubvf8HDgLuGSI6Y4Gjhxiw5R96L55OA84lu7biA8CHwZWbxujXAbs0ub7D+Ac4DLgkqr6bp9476erqjys3TsP2H50b0aSJEmSJEmLW7rclLR0mLH+BvWjgw6Z6DAkSZIkSdIyau23vXaiQ1jkksytqpn9rll5KEmSJEmSJKkvk4eSJEmSJEmS+nK3ZS1Vll97jUdkebAkSZIkSdJkZOWhJEmSJEmSpL5MHkqSJEmSJEnqy2XLWqrc/4fr+J/P7DHRYUiSJEkjWm//Eyc6BEmSFpqVh5IkSZIkSZL6MnkoSZIkSZIkqS+Th5IkSZIkSZL6MnkoSZIkSZIkqa9lKnmY5HFJjk9yXZIrk5yRZJMlHMO0JG8f5vpdSzieZySpJC9ckvP2iWPfJOtOZAySJEmSJEl6uGUmeZgkwMnAuVW1YVVtBrwPWGcMY0wZdD6e3aqnAUMmDyfAnsD57e9E2hcweShJkiRJkjSJLDPJQ2AX4K9VdeRAQ1XNq6qfJtk5yWkD7UmOSLJvO74hycFJzgdeleTcJB9Nch7wriRrJzkpycXtt0O7b1aSo1r/XyfZvw1/KLBhknlJDh9N4EnWT/LjJPPb3/Va+0uTXJjk0iRnJVlnhLkHjxtgD7rE3QuSrNjapyf5ZZIvJ7kiyXFJdk1yQZJrk2zb+q2R5JQW1y+SbNkz/wE981zRxpye5KokX0qyIMmZSVZKsgcwEziuvZeVRvNeJEmSJEmStHgtS8nDLYC547z33qrasaqOb+fTquo5VfVJ4NPAp6pqG+CVwJd77nsK8EJgW+ADSVYADgKuq6oZVXXgKOc/AvhaVW0JHAd8prWfDzyrqp4BHA+8d4S5B9sBuL6qrgPOBf6x59pG7dm2bGPtBewIHEBXsQnwQeDSFtf7gK+N4lk2Bj5XVZsDtwOvrKoTgTnA3u293NN7Q5L9ksxJMue2u+4bxRSSJEmSJElaFMaz7HZZ9K1hzncFNuuK+ABYNcnUdnx6Vd0H3JfkD4xhifQg2wGvaMfHAh9vx08EvpXk8cCjgOt77uk3902Dxt2TLulI+7sP8J12fn1VXQ6QZAHw46qqJJcD01ufHekSplTV2UnWTLLaCM9yfVXNa8dze8YaUlXNBmYDbLne6jVSf0mSJEmSJC0ay1LycAHdEt1+HuDhVZgrDrp+9zDnywHb9amWA+gtk3uQRfe+BxJonwX+q6pOTbIzMKunz7Bzt+83vhJ4WZL3AwHW7El89t7/UM/5Qz1jhb9XDP8+B8flEmVJkiRJkqRJallatnw28Ogkbx5oSLJNkucAv6GrHnx0q5x73hjGPRN4R8+YM0bofycwdYQ+g/0MeE073ptuuTLAasBv2/HrxzjmrsBlVfWkqppeVesDJwG7jWGMn7R4aMnLW6vqDuAGYKvWvhXw5FGMNZ73IkmSJEmSpMVomUkeVlUBuwPPT3JdW4o7C/hdVd0InADMp/um4KVjGHp/YGbbNORK4K0jxPFH4IK2iUi/DVNWTnJTz+9f2xxvSDKfbmnxu1rfWcC3k/wUuHUMMUO3ZPnkQW0n0X3bcLRm0Z6dbiOYgQTmScAaSeYBbwOuGcVYRwNHumGKJEmSJEnS5JEupyYtHbZcb/U67YCxFIZKkiRJE2O9/U+c6BAkSRqVJHOrama/a8tM5aEkSZIkSZKksTF5KEmSJEmSJKmvZWm3ZT0CPOqxG7r8Q5IkSZIkaQmx8lCSJEmSJElSXyYPJUmSJEmSJPVl8lCSJEmSJElSX37zUEuVO269lh9+5R8nOgxJ0gR44ZvOmOgQJEmSpGWOlYeSJEmSJEmS+jJ5KEmSJEmSJKkvk4eSJEmSJEmS+jJ5uIQl2T1JJXnKBMx9Q5K1RtsuSZIkSZKkZZvJwyVvT+B84DUTHYgkSZIkSZI0HJOHS1CSVYAdgDfRkzxMsnOSc5OcmOSXSY5LknbthiQfTHJJkssHKhaTzEpyQM8YVySZ3o5PSTI3yYIk+40hvulJrkrypXbvmUlWatc2SnJWkstaLBumc3ib+/Ikr+55nvOSnJDkmiSHJtk7yUWt34at39pJTkpycfvtsJCvWJIkSZIkSYuQycMlazfgB1V1DXBbkq16rj0DeDewGbABXZJxwK1VtRXwBeAARvbGqtoamAnsn2TNMcS4MfC5qtocuB14ZWs/rrU/HdgeuBl4BTADeDqwK3B4kse3/k8H3gU8DdgH2KSqtgW+DLyz9fk08Kmq2qbN8+V+ASXZL8mcJHP+fOf9Y3gUSZIkSZIkLQyTh0vWnsDx7fj4dj7goqq6qaoeAuYB03uufaf9nTuofSj7J7kM+AXwJLqE4GhdX1XzeudLMhV4QlWdDFBV91bVX4AdgW9W1YNV9b/AecA27d6Lq+rmqroPuA44s7Vf3vMMuwJHJJkHnAqs2uZ6mKqaXVUzq2rmalMfNYZHkSRJkiRJ0sJYfqIDWFa06r/nAlskKWAKUEne27rc19P9QR7+b3Nfn/YHeHjyd8U2z850SbntquovSc4duDZKg+NYCcgQfYdqHzzOQz3nD/G3Z1iuxXnPGOKTJEmSJEnSEmLl4ZKzB/C1qlq/qqZX1ZOA6+mq98bjBmArgLb8+cmtfTXgTy1x+BTgWQsXNlTVHcBNSXZr8z06ycrAT4BXJ5mSZG1gJ+CiMQx9JvCOgZMkMxY2VkmSJEmSJC06Jg+XnD2Bkwe1nQTsNc7xTgLWaEt+3wZc09p/ACyfZD7wIbqly4vCPnTLoecDPwMeR/c884HLgLOB91bV78cw5v7AzCTzk1wJvHURxSpJkiRJkqRFIFU10TFIo7bJ9NXqs//ppsyStCx64ZvOmOgQJEmSpEekJHOrama/a1YeSpIkSZIkSerL5KEkSZIkSZKkvtxtWUuVVdfa2GVrkiRJkiRJS4iVh5IkSZIkSZL6MnkoSZIkSZIkqS+Th5IkSZIkSZL68puHWqrc8sdr+eKxL5zoMKRF7i37/HCiQ5AkSZIk6e9YeShJkiRJkiSpL5OHkiRJkiRJkvoyeShJkiRJkiSpL5OHkiRJkiRJkvoyeTiJJKkkx/acL5/kliSnjXO8aUne3nO+81BjJTk3ycwxjH1Dksvb78okH07y6BHumZ7kiiGuvTvJyqOdX5IkSZIkSYufycPJ5W5giyQrtfPnA79diPGmAW8fsdf47VJVTwO2BTYAZi/EWO8GTB5KkiRJkiRNIiYPJ5/vAy9ux3sC3xy4kGSNJKckmZ/kF0m2bO2zkhzVqgd/nWT/dsuhwIZJ5iU5vLWtkuTEJL9MclyS9E6e5E1JPtVz/uYk/zVcwFV1F/BWYLcka7T7DkxycYv1gz3dl09yTGs/McnKLd51gXOSnDPG9yVJkiRJkqTFxOTh5HM88JokKwJbAhf2XPsgcGlVbQm8D/haz7WnAC+kqwL8QJIVgIOA66pqRlUd2Po9g67KbzO6asEd+sz/snY/wBuAr44UdFXdAVwPbJzkBcDGLZYZwNZJdmpdNwVmt2e4A3h7VX0G+B1dJeMug8dOsl+SOUnm3HXn/SOFIkmSJEmSpEXE5OEkU1Xzgel0VYdnDLq8I3Bs63c2sGaS1dq106vqvqq6FfgDsM4QU1xUVTdV1UPAvDZX7/x3A2cDL0nyFGCFqrp8lOEPVDG+oP0uBS6hS2xu3K7dWFUXtOOvt2caVlXNrqqZVTVzlamPGmUokiRJkiRJWljLT3QA6utU4BPAzsCaPe3p07fa3/t62h5k6H/b0fT7Ml1l4y8ZRdUhQJKpdInIa1qcH6uqLw7qM70n3gGDzyVJkiRJkjRJWHk4OR0FHNKn4u8nwN7Q7ZwM3NqWCw/lTmDqWCevqguBJwF70fPNxaEkWQX4PHBKVf0J+CHwxtZOkickeWzrvl6S7drxnsD5CxOrJEmSJEmSFh8rDyehqroJ+HSfS7OAryaZD/wFeP0I4/wxyQVJrqDbiOX0MYRxAjCjJQOHck7bcGU54GTgQ23eM5M8Ffh524/lLuC1dJWOVwGvT/JF4FrgC22s2cD3k9zc77uHkiRJkiRJWvJS5apR/b0kpwGfqqofT3QsvdZ/8mr1vkOeNdFhSIvcW/b54USHIEmSJElaRiWZW1Uz+11z2bIeJsm0JNcA90y2xKEkSZIkSZKWLJct62Gq6nZgk4mOYyhrr7mxFVqSJEmSJElLiJWHkiRJkiRJkvoyeShJkiRJkiSpL5OHkiRJkiRJkvrym4daqtxw+7W84eQXTXQYWgZ9dfcfTHQIkiRJkiQtcVYeSpIkSZIkSerL5KEkSZIkSZKkvkweSpIkSZIkSerL5KEkSZIkSZKkviZV8jBJJflkz/kBSWYtorGPTrLHohhrhHleleSqJOf0ubZ5krOTXJPk2iT/mSSLO6Y292VJvrkk5hpJkvdNdAySJEmSJEka2aRKHgL3Aa9IstZEB9IryZQxdH8T8Paq2mXQGCsBpwKHVtUmwNOB7YG3L7JAh5DkqXT/1jsleczinm8UTB5KkiRJkiQtBSZb8vABYDbwnsEXBlcOJrmr/d05yXlJTmgVfYcm2TvJRUkuT7JhzzC7Jvlp6/eSdv+UJIcnuTjJ/CRv6Rn3nCTfAC7vE8+ebfwrkhzW2g4GdgSOTHL4oFv2Ai6oqjMBquovwDuAg9q9s5Ic2yoTr03y5p65DuyJ74OtbXqrcPxSkgVJzmwJyn72Ao4FzgRe1jPuRknOalWJlwy8qyTvbc92WZJDW9uMJL9oMZycZPXWfm6Sme14rSQ3tON9k3wnyQ/a83y8tR8KrJRkXpLjkjwmyeltriuSvHqIZ5AkSZIkSdIStvxEB9DH54D5A8mmUXo68FTgNuDXwJeratsk7wLeCby79ZsOPAfYEDgnyUbA64A/V9U2SR4NXJDkzNZ/W2CLqrq+d7Ik6wKHAVsDfwLOTLJbVR2S5LnAAVU1Z1CMmwNzexuq6rokqyRZtTVtCTwLeAxwaZLTgS2AjVssAU5NshPwP619z6p6c5ITgFcCX+/zfl4NPB/YlC5hObB8+Ti6SsiTk6wILJfkH4DdgGdW1V+SrNH6fg14Z1Wdl+QQ4AM973UoM4Bn0FWUXp3ks1V1UJJ3VNWM9i5fCfyuql7czlcbPEiS/YD9AB6z9oojTClJkiRJkqRFZbJVHlJVd9AlqvYfw20XV9XNVXUfcB1dhR10FYPTe/qdUFUPVdW1dEnGpwAvAF6XZB5wIbAmXVIO4KLBicNmG+Dcqrqlqh6gS8LtNEKMAWqIawPt362qe6rqVuAcuoThC9rvUuCSFvNAfNdX1bx2PHfQs3aTJtsAt1TVb4AfA1slWT3JVOAJVXUyQFXd26ohdwW+2o6pqttaQm9aVZ3Xhj1mFM8L8OOq+nNV3QtcCazfp8/ldBWhhyV5dlX9+e9eTtXsqppZVTNXXPVRo5hWkiRJkiRJi8KkSx42/0337cDe7/M9QIu3bTLSm0W6r+f4oZ7zh3h4deXg5F3RJfXeWVUz2u/JA0uLgbuHiG88m5wsAGY+bJBkA+CuqrpzhPg+1hPfRlX1lXa997kfpH8l6Z7AU9py4uuAVekqFId6huGSnP38378LMLgscMT4quoaugrOy4GPtaXfkiRJkiRJmgQmZfKwqm4DTqBLIA64gS7JBPByYIVxDP2qJMu1b/ttAFwN/BB4W5IVAJJsMopNRS4EntO+8TeFLkF33gj3HAfsmGTXNs9KwGeA3uXZL0+yYpI1gZ2Bi1t8b0yySrvvCUkeO5qHTbIc8Cpgy6qaXlXT6d7dnq3C86Yku7W+j06yMl3V5hvbMUnWaNWAf0ry7Db0Pj3PewN/+3cZ7W7Wf+153+sCf6mqrwOfALYa5RiSJEmSJElazCbjNw8HfJLu+3wDvgR8N8lFdMtvh6oKHM7VdEmvdYC3VtW9Sb5Mt9z3klbReAvdN/+GVFU3J/kPuqXFAc6oqu+OcM89SV4OfDbJ54ApdJuYHNHT7SLgdGA94ENV9Tvgd+l2S/55Fx53Aa+lq+QbyU7Ab6vqtz1tPwE2S/J4uiTgF9s3DP8KvKqqfpBkBjAnyf3AGXS7I7+ebiOYlemWfL+hjfcJ4IQk+wBnjyIm6DbFmZ/kErol6ocneajF8LZRjiFJkiRJkqTFLFVjWaGqxSXJLLolzJ+Y6Fgms7U2Wq1eevh2Ex2GlkFf3f0HEx2CJEmSJEmLRZK5VTWz37VJuWxZkiRJkiRJ0sSbzMuWlylVNWuiY5AkSZIkSZJ6mTzUUmX6tI1dPipJkiRJkrSEuGxZkiRJkiRJUl8mDyVJkiRJkiT1ZfJQkiRJkiRJUl9+81BLlWtv/z0vPvnwiQ5DS6nTdz9wokOQJEmSJGmpYuWhJEmSJEmSpL5GTB4mWSfJV5J8v51vluRNiz80SZIkSZIkSRNpNJWHRwM/BNZt59cA715cAUmSJEmSJEmaHEaTPFyrqk4AHgKoqgeABxdrVItAkkpybM/58kluSXLaOMd7WZKDFl2EY57/UUn+O8l1Sa5N8t0kT1wC826S5Iwkv0pyVZITkqyzEOPNSnJAOz4kya7t+N1JVl5UcUuSJEmSJGnhjSZ5eHeSNYECSPIs4M+LNapF425giyQrtfPnA78d72BVdWpVHbpIIhufjwJTgU2qamPgFOA7SbK4JkyyInA68IWq2qiqngp8AVh7UL9xbbxTVQdX1Vnt9N2AyUNJkiRJkqRJZDTJw38FTgU2THIB8DXgnYs1qkXn+8CL2/GewDcHLiTZNsnPklza/m7a2v81yVHt+GlJrkiycpJ9kxzR2o9O8oUk5yT5dZLnJDmqVeYd3TPHXT3HewxcG+39PfeuDLwBeE9VPQhQVV8F7gOem2R6kl8mOSbJ/CQnDlTxJdk6yXlJ5ib5YZLHt/ZzkxyW5KIk1yR5dp/3txfw86r63kBDVZ1TVVe09/HtJN8DzmxjHpjk4hbDB3vif3+Sq5OcBWza0350ey/70y2LPyfJOcP9g0qSJEmSJGnJGTZ5mGQ5YEXgOcD2wFuAzatq/hKIbVE4HnhNq6DbEriw59ovgZ2q6hnAwXSVfQD/DWyUZHfgq8BbquovfcZeHXgu8B7ge8CngM2BpyWZMYrYxnL/RsD/VNUdg9rntHugS8rNrqotgTuAtydZAfgssEdVbQ0cBXyk5/7lq2pbuqq/D/SJcQtg7jDPsB3w+qp6bpIXABsD2wIzgK2T7JRka+A1wDOAVwDbDB6kqj4D/A7Ypap2GXw9yX5J5iSZc/8ddw8TjiRJkiRJkhalYZebVtVDST5ZVdsBC5ZQTItMVc1PMp2u6vCMQZdXA45JsjHdkuwV2j0PJdkXmA98saouGGL471VVJbkc+N+quhwgyQJgOjBvhPDGcn9ajIP1tt/YE+vXgf2BH9AlAH/UVjdPAW7uuf877e/cNudY/aiqbmvHL2i/S9v5KnTJxKnAyQMJ2CSnjnWSqpoNzAZYbaMn9nsPkiRJkiRJWgxGs2z5zCSvXLRKbYEAACAASURBVJzf1lvMTgU+Qc+S5eZDwDlVtQXwUroKywEbA3fxtx2m+7mv/X2o53jgfCAp25vo6h1/tPcP+BWwfpKpg9q3Aq7sM9fAeYAFVTWj/Z5WVS/oE8ODfeaELmG8dZ/2Ab1lgAE+1jPXRlX1lSFikyRJkiRJ0lJgtN88/DZwX5I7ktyZZPDy2cnsKOCQgcq+Hqvxtw1U9h1oTLIa8GlgJ2DNJHssxNz/m+Spbfn37uMdpKruBo4B/ivJlBbn6+g2GDm7dVsvyXbteE/gfOBqYO2B9iQrJNmc0fsGsH2Sge9GkuRFSZ7Wp+8PgTcmWaX1e0KSxwI/AXZPslJLfr50iLnupKtSlCRJkiRJ0iQxYvKwqqZW1XJV9aiqWrWdr7okglsUquqmqvp0n0sfBz7WNoGZ0tP+KeDzVXUN8Cbg0JYEG4+DgNPoEnw3j9B3JP8B3Atck+Ra4FXA7lU1UNV3FfD6JPOBNeh2SL4f2AM4LMlldEuhtx/thFV1D/AS4J1Jrk1yJV2i9Q99+p5Jl2z8eVuKfSIwtaouAb7V5j4J+OkQ080Gvu+GKZIkSZIkSZNH/pZ7GqJDslO/9qr6yWKJSGPWvut4WluC/Yi22kZPrB0Pf9dEh6Gl1Om7HzjRIUiSJEmSNOkkmVtVM/tdG3bDlKb3/7ZXpNtNdy7dTsGSJEmSJEmSHqFGTB5W1cO+UZfkSXRLfjVJVNUNdLsqS5IkSZIkSYvMaCoPB7sJE1WaIBtPe5xLTyVJkiRJkpaQEZOHST4LDHwYcTlgBnDZ4gxKkiRJkiRJ0sQbTeXhnJ7jB4BvVtUFiykeSZIkSZIkSZPEaJKH06rq070NSd41uE2SJEmSJEnSI0uqavgOySVVtdWgtkur6hmLNTKpj2kbblA7HvahiQ5Dk9Rpe+w90SFIkiRJkrTUSTK3qmb2uzZk5WGSPYG9gCcnObXn0lTgj4s2REmSJEmSJEmTzXDLln8G3AysBXyyp/1OYP7iDEqSJEmSJEnSxBsyeVhVvwF+A2y35MKRJEmSJEmSNFksN1KHJM9KcnGSu5Lcn+TBJHcsieAkSZIkSZIkTZwRk4fAEcCewLXASsA/A59dnEEtjCSPS3J8kuuSXJnkjCSbLOEYpiV5+5KKMcm+SY5ox29N8rqe9nWHuOfoJNcnmZfkl0k+MIp5jk6yx3jjlCRJkiRJ0tJlNMlDqupXwJSqerCqvgrssnjDGp8kAU4Gzq2qDatqM+B9wDpjGGPKoPPhvgs5lGlA3+ThaGMcHMdoVdWRVfW1drov0Dd52BxYVTOAGcDrkzx5PHNKkiRJkiTpkWk0ycO/JHkUMC/Jx5O8B3jMYo5rvHYB/lpVRw40VNW8qvppkp2TnDbQnuSIJPu24xuSHJzkfOBVSc5N8tEk5wHvSrJ2kpPa8u2Lk+zQ7puV5KjW/9dJ9m/DHwps2Kr6Dh9jjOck+QZweZvjtUkuamN9cSCpmOQNSa5pMe7Q81yzkhzQKgRnAse1e1ca5r2t2P7e3cY4uD3nFUlmt4TnwwzVp72Lw1rM1yR5dmufkuQTSS5PMj/JO1v71knOSzI3yQ+TPH6YOCVJkiRJkrQEjSZ5uE/r9w665NKTgFcuzqAWwhbA3HHee29V7VhVx7fzaVX1nKr6JPBp4FNVtQ3ds3+5576nAC8EtgU+kGQF4CDguqqaUVUHjjHGbYH3V9VmSZ4KvBrYoVUIPgjs3RJsH6RLGj4f2GzwIFV1IjAH2LvFcU+fuQ5PMg+4CTi+qv7Q2o+oqm2qagu6peov6XPvcH2Wr6ptgXcDA8uh9wOeDDyjqrakS2quQLcEfo+q2ho4CvjI4ImS7JdkTpI599/h5zYlSZIkSZKWlBGX5FbVb1rV2uOr6oNLIKaJ8q1hzncFNuspwFs1ydR2fHpV3Qfcl+QPjGGJ9BAuqqrr2/HzgK2Bi9vcKwF/AJ5Jt+z5FoAk3wLG883EA6vqxCSrAD9Osn1V/QzYJcl7gZWBNYAFwPcG3Ttcn++0v3OB6e14V+DIqnoAoKpuS7IFXTL1R+35pgA3Dw6yqmYDswGmbbhBjeM5JUmSJEmSNA4jJg+TvBT4BPAo4MlJZgCHVNXLFndw47AAGGpDjwd4eKXlioOu3z3M+XLAdoOr91rC676epgcZ+Z0OF+PgeQMcU1X/MWje3YBFlkSrqruSnAvsmOQS4PPAzKq6McksBr2rJCuO0GfgnfS+j/SJOcCCqtpuUT2LJEmSJEmSFp3RLFueRbeU9nbovs/H36rJJpuzgUcnefNAQ5JtkjwH+A1d9eCjk6xGV9U3WmfSLdseGHPGCP3vBKYOcW24GAf7MbBHkse2fmskWR+4ENg5yZpt6e+rxhHH/2mbwjwTuI6/JQFvbRWJ/RKdo+kz2JnAWwc2oEmyBnA1sHaS7VrbCkk2H8VYkiRJkiRJWgJGkzx8oKr+vNgjWQSqqoDdgecnuS7JArrk5++q6kbgBGA+cBxw6RiG3h+Y2Tb6uBJ46whx/BG4oG0mcviga0PG2GecK4H/B5yZZD7wI7rl4ze3e34OnAVcMkQoRwNHDrNhysA3D+fTbdDynaq6HfhSOz8FuLhPXCP26ePLwP8A85NcBuxVVffTJR4Pa23zgO1HMZYkSZIkSZKWgHS5rGE6JF+hq4A7iG6zkP2BFapq2ASatDhM23CD2vGwD010GJqkTttj74kOQZIkSZKkpU6SuVU1s9+1ISsPkxzbDq8DNqf7jt03gTvodtGVJEmSJEmS9Ag23OYeW7fv670a2AX4ZM+1lYF7F2dgUj8brb6G1WWSJEmSJElLyHDJwyOBHwAbAHN62gd2zd1gMcYlSZIkSZIkaYINuWy5qj5TVU8FjqqqDXp+T64qE4eSJEmSJEnSI9yIuy1X1duWRCCSJEmSJEmSJpfhli1Lk86v/nQnu53444kOQ32cssfzJjoESZIkSZK0iI1YeShJkiRJkiRp2WTyUJIkSZIkSVJfJg8lSZIkSZIk9WXyUJIkSZIkSVJfj8jkYTrnJ/mHnrZ/SvKDCY7phCTzk+zf5/q+Sa5IsqD93rOQ892UZFqSKUl+2to2SPKaIfpvlGTeoLYPJ3l3O/5Ikl2Gme8VSZ6yMDFLkiRJkiRpcnlE7rZcVZXkrcC3k5wDTAE+ArxoYcZNsnxVPTDO258AbF1VG/YZ9yXAO4Bdq+r3SVYC9l4U81fVg8Cz2+kGwGuA48cafFW9f4QurwAeAn452jEX8n1KkiRJkiRpMXtEVh4CVNUVwPeAfwc+AHytqq5L8vokFyWZl+TzSZYDSDI7yZxW9XfwwDitgu8/k1wA7J7kPUmuTHJZkq8PnjfJSkmOSXJ5kkuS7NQunQms2+bdftBt7wP+tap+32K/p6q+3MY7v1X9/QR4R5J1knynxXpRkme1fmsn+VGb8wtAWvvySW5v8xwK7NJi+Lvqx+Ek+XqS3drx4e0dzE9yWJJnA/8IfKqNPT3JVkkubH1OSrLaEM/z6yTLt2vTklyfZMpYYpMkSZIkSdLi8YisPOzxQeAS4H5gZpItgN2B7avqgSSz6SrxvgEcVFW3tUTWOUlOrKor2zh3V9UOAEluBtavqvuTTOsz5/7A/VX1tCSbA2ck2Rh4GXBiVc3oc8/mwNxhnmPVqtqpzf8t4ONV9Ysk04HTgC3as55TVR9N8nLgrX3GOQh4R1XtNsQ8mw5auvw4uoTj/0myDl2icPNW4Tmtqm5PckZ7vlNavzOA/arq/CQfBf4TOKDP82xNVxF6GrAXcEKrluydcz9gP4CV1nrsMK9JkiRJkiRJi9IjOnlYVXe3ZNtdVXVfkl2BbYA5SQBWAm5s3fdM8ia6d7IusBkwkDz8Vs+wC4CvJ/kucEqfaXcEDm/zL0jyO2AjugTmePUuM96VLsk3cL56W+a8E11Sj6r6bpI7xzHP1b3JzSQf7tPnNrrlyV9Kcjpd0u9hkqwJrFhV57emY4Bjh3ieL9MlXE8D3gDsM3i8qpoNzAaYtuGmNZYHkiRJkiRJ0vg9Ypct93io/aBbyntUVc1ov02r6kOtMvBdwHOrakvgB8CKPWPc3XP8QuBIYFu6JOTgJbZh7K4Eth7meu/8AbbteYYnVNU97dpiT6xV1V+BmXSJ01cCp/fpNtI7+L/nqarzgE3aZix/rapRfzNRkiRJkiRJi9eykDzsdRbwT0nWgq5CLsl6wKrAncAdSR5PlyD8Oy1R+MSqOhs4EFgbWHlQt5/QNjtJ8lTg8cCvRojrY8An2pJgkqyY5J3DPMO/9MQ0UCnYO+9Lgal97r1ziPZRSzKVbtnxacB7gGcMHruqbgXu6fm24z7AecMM+3XgOOCrCxObJEmSJEmSFq1lKnlYVZfTfRvwrCTz6TYxWYfuu4hXAlcAXwIuGGKI5YFvtHsvAQ6rqsHLgz8LrJTkcrqE2Ouqatgly1V1KvBF4OwkC4A5DP1v8y/ADm0jkiuBN7f2DwC7JrkE2Bn4bZ97LwWmtM1exrRhSo/VgNOTXAacDfxra/8m8L6BDVPoEoafau9qM6DfEugBx7VxvzVMH0mSJEmSJC1hqfITcppYSV4DvLCq3jBS32kbblo7H/b5JRCVxuqUPZ430SFIkiRJkqRxSDK3qmb2u/aI3jBFk1+SL9BtAvOiiY5FkiRJkiRJD2fyUBOqqt420TFIkiRJkiSpP5OHWqpstPpUl8dKkiRJkiQtIcvUhimSJEmSJEmSRs/koSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJkiRJ6mv5iQ5Ai0eSNYEft9PHAQ8Ct7Tzbavq/nGOexOwRVXd3tO2O7BRVR2+ECFLkiRJkiRpkjF5+AhVVX8EZgAkmQXcVVWfWExznbw4xpUkSZIkSdLEctnyMijJ95LMTbIgyT+3tg2SXJtkjSRTkvwsyXNHOd4/J/nvdrxOku8kmZPkoiTPau0fTvKVJOcl+XWSf2ntU5N8P8llSa5Issfiem5JkiRJkiSNjZWHy6bXV9VtSVYG5iQ5qap+neSTwOeBy4BLq+rscYz9GeDjVfWLJNOB04At2rVNgOcB04CrkhwJ/CNwQ1X9A0CS1QYPmGQ/YD+A9dZbbxwhSZIkSZIkaTysPFw2vSfJZcDPgScCGwJU1ZHA2sAbgPeOc+xdgSOTzANOAVZPslK7dlpV3V9VfwBua3PNB16U5NAkO1TVnwcPWFWzq2pmVc1ce+21xxmWJEmSJEmSxsrKw2VMkl2BnYBnVdU9Sc4HVmzXVgEeD0wBVgHuHs8U9NmQJQnAfT1NDwLLV9VVSWbSVSAenuS0qvroOOaVJEmSJEnSImbl4bJnNeC2ljjcHNim59rhwNHAIcAXxzn+WcC/DJwkmTFc5yRPoNvM5Vjgv4CtxjmvJEmSJEmSFjGTh8ue04GV27Llg4ELAZI8D3g68MmqOgZYLsk+Q4yxIMlN7ffxQdf+BdghyfwkVwJvHiGepwMXt2XO7wWsOpQkSZIkSZokUlUTHYM0ajNnzqw5c+ZMdBiSJEmSJEmPGEnmVtXMftesPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPJQkSZIkSZLU14QmD5NUkk/2nB+QZNYiGvvoJHssirFGmOdVSa5Kck6fa5skOSPJr1qfE5KssxBzzUpyQDs+JMmu7fjdSVYe4p5zk1yd5LIkFyTZdIxznptkZp/2fZMcMZ7nkCRJkiRJ0tJhoisP7wNekWStCY7jYZJMGUP3NwFvr6pdBo2xInA68IWq2qiqngp8AVh7UL/lxxNjVR1cVWe103cDfZOHzd5V9XTgGODwwRfH+LySJEmSJElaRkx08vABYDbwnsEXBlcOJrmr/d05yXmtiu+aJIcm2TvJRUkuT7JhzzC7Jvlp6/eSdv+UJIcnuTjJ/CRv6Rn3nCTfAC7vE8+ebfwrkhzW2g4GdgSOTDI4KbcX8POq+t5AQ1WdU1VXtKq9byf5HnBmG+vAnpg+2DPv+1vl4FnApj3tRyfZI8n+wLrAOf2qHwf5CbBRu/+GJAcnOR94VZIZSX7R5j85yeo99702yc/as2/b592sneSkFv/FSXZo7bOSHJPkzDbfK5J8vL3HHyRZofU7NMmVbe5PjPAMkiRJkiRJWkLGVfW2iH0OmJ/k42O45+nAU4HbgF8DX66qbZO8C3gnXSUe8P/bu/dgy8ryzuPfHzQB5NJ4YSw107YiFCDBZjgyUeSmSKgQBSKWeAtGJxQqKFpURhMrQZxMMDqJRrxwkVEZBlBEJYACclXk1kDbKJEgYGYYKEGbAhG6pbuf+WO9R3cf9jm9e58+F875fqpO9V7rXe9l7f3U6rOf875rsRjYD9iBLrn2EuDPgEeq6uVJNgeuS3JZO34vYLequre3syTPBz4O7Ak8DFyW5LCqOinJq4ETqmrpmDHuBtwywTm8Ati9qlYkOQjYsfUf4MIk+wK/Bo4E9qD7rG4d22ZV/XOSDwIHVNUvJn7beB3rJkZXVtWr2jkuB46rqmuSnAT8Lb97H7eqqle2MZ3Zzq3Xp4F/qqrvJ1kEXEr3+UD33h8A7ApcD7yhqv4yyTeAQ5JcCxwO7FxVlWS7sYNOcjRwNMCiRYvWc4qSJEmSJEnaWGY8eVhVjyb5CvA+4IkBq91cVQ8AJLmbNnuPLjHWu3z4q1W1FrgryT3AzsBBwO49sxoX0iXufgPcNDZx2LwcuLqqHmp9ng3sC3xzwPH2c3lVrWivD2o/t7XtrduYtgG+UVWPt34vHLKvs5M8AfyMLrk66rzW7kJgu6q6pu3/MvC1nuPOAaiqa5Ns2yfBdyCwa5LR7W2TbNNef7uqnkxyO7Ap8J22/3a65O5FwErgjCQXt+11VNVpdDNUGRkZqQ04b0mSJEmSJE3CjCcPm0/Rzar7nz37VtOWVafLSv1eT9mqntdre7bXsu45jU00Fd3MvuOq6tLegiT708306yfj7J/Ij+lmPY6nt68Af19Vp44Z0/E89RyG8dY+MyPHjmEi/d7HXpsAr6iqdZK/LZm4CqCq1iZ5sqpG664FFlTV6rYU+jV0syyPBV494LgkSZIkSZI0hWb6nocAtBl4X6V7+Mion9EtEwY4FNhsiKbfmGSTdh/EFwN30i2pfXfP/fZ2SrLVetq5EdgvyXPaw0XeDFyznjr/G3hlkkNGdyQ5OMkf9Dn2UuCdSbZux70gyX+gu0fh4Um2bDP5XjdOX7+im6U4lKp6BHg4yT5t19tZ9/ze1Mb1Krol34+MaeIyuqQf7bglg/bdznlhVV1Ct0x64LqSJEmSJEmaWrNl5iHA/6AnAQWcDnwryU3AFQw+S67XnXRJsOcCx1TVyiRn0C2XvbXNaHwIOGyiRqrqgSQfBq6imyV4SVV9az11nmgPaflUkk8BTwLLgff3OfayJLsA17fZeo8Bb6uqW5OcBywD/h343jjdnQZ8O8kDY5/6vAGOonvwyzPo7iP55z1lDyf5AbAt8M4+dd8HfLbdN3EBXdLzmAH73Ybuc96C7r19ysNzJEmSJEmSNDPyu1Wk0uw3MjJSS5f2W4EtSZIkSZKkYSS5papG+pXNimXLkiRJkiRJkmYfk4eSJEmSJEmS+jJ5KEmSJEmSJKkvk4eSJEmSJEmS+jJ5KEmSJEmSJKkvk4eSJEmSJEmS+jJ5KEmSJEmSJKkvk4eSJEmSJEmS+jJ5KEmSJEmSJKkvk4eSJEmSJEmS+pqy5GGSSnJWz/aCJA8luWjI9rZL8p6e7f2HbWuc9p+f5PyN1V6f9hcn+dGQdf9qwOPekeSUQY9JckySPxtmTBvT2M9WkiRJkiRJs8NUzjz8NbBbki3b9muB/zeJ9rYDpizBVFX3V9URU9X+JA2UPNxQVfWFqvrKVLS9gab0s5UkSZIkSdJwpnrZ8reBQ9rrNwPnjBYkeVaSbyZZnuSGJLu3/ScmOTPJ1UnuSfK+VuVkYIcky5J8ou3bOsn5SX6S5OwkaW2cnOSO1vYnxw4qyX6tnWVJbkuyTe/MwDY774Ik30lyV5J/6Kl7cJJbk/wwyRVt31ZtzDe39g6d6E1pfX2vtXNrkle2/c9Lcm0b14+S7JPkZGDLtu/sPm39eZJ/S3INsHfP/u2TfL2N6eYke/epe2KSE9rrq5N8PMlNrb192v4tk5zb3svzktyYZKSVPdbT1hFJvjRR3xv42UqSJEmSJGmGLZji9s8F/qYtL94dOBPYp5V9FLitqg5L8mrgK8CSVrYzcACwDXBnks8DHwJ2q6ol0C1bBvYAXgrcD1wH7J3kDuBwYOeqqiTb9RnXCcB7q+q6JFsDK/scs6S1v6qN4TPtuNOBfavq3iTPasf+NXBlVb2z9XdTku9W1a/HeV8eBF5bVSuT7EiXVB0B3gJcWlV/l2RT4BlV9b0kx46ed68kz2vv457AI8BVwG2t+NPAP1XV95MsAi4FdhlnPKMWVNVeSf4Y+FvgQODdwONVtXtL8N66njbW1/d6P9s+53k0cDTAokWLBuhekiRJkiRJG8OUJg+ranmSxXSzDi8ZU/wq4A3tuCuTPDvJwlZ2cVWtAlYleRB47jhd3FRV9wEkWQYsBm6gS/KdkeRioN99Ea8D/rHN5Lugqu5rkxZ7XVFVj7S27wBeCDwTuLaq7m3jXtGOPQh4/egsPmALYBHwr+OMezPglCRLgDXATm3/zcCZSTYDvllVy8apP+o/A1dX1UNtnOf1tHUgsGvPeW2bZJv1tHdB+/cWuvcSYF/gn+G3n+fy9bSxvr4H/Wx/q6pOA04DGBkZqQH6lyRJkiRJ0kYw1TMPAS4EPgnsDzy7Z/9TsnXAaGJoVc++NYw/zqccV1Wrk+wFvAY4EjgWePU6nVSd3BKLfwzckORAnjr7sN8Y0jPGXgHeUFV3jjPOsT4A/Bx4Gd3S8ZVtXNcm2ZduqfdZST4xwD0Jx0umbQK8oqqeWGegT02S9ho957Hv+Xh99O7fYsC+B/1sJUmSJEmSNMOm+p6H0C1VPqmqbh+z/1rgrfDbJci/qKpHJ2jnV3RLXSfUliEvrKpLgOP53VLo3mN2qKrbq+rjwFK6pbSDuB7YL8mLWjujy5YvBY5LfnvPxT3W085C4IGqWgu8Hdi01Xsh8GBVnQ58EfhP7fgn22zEsW4E9m+zNjcD3thTdhld4nT0nPsuCR5A7+e0G93y81E/T7JLkk3olooP2/dAn60kSZIkSZKm15QnD6vqvqr6dJ+iE4GRtgz2ZOCo9bTzS+C69iCRiR6qsQ1wUWv3GrpZfmMd39r5IfAE3YNd1qstDz4auKDVPa8VfYxuKfLydA9d+dh6mvoccFSSG+iWGY/eG3F/YFmS2+iWdI++b6e1ttd5YEpVPUD3Pl4PfJd170f4Ptr725ZdHzPIOfbxeboH0ywH/hK4qafsQ3TLwq8EHhi27w34bCVJkiRJkjSNUuUt5DS4JFcDJ1TV0pnof2RkpJYunZGuJUmSJEmS5qQkt1TVSL+y6Vi2LEmSJEmSJOlpyIdVaINU1f4zPQZJkiRJkiRND2ceSpIkSZIkSerL5KEkSZIkSZKkvkweSpIkSZIkSerL5KEkSZIkSZKkvkweSpIkSZIkSerL5KEkSZIkSZKkvkweSpIkSZIkSerL5KEkSZIkSZKkvkwezkJJ1iRZluSHSW5N8spJtHV1kpGNOb7W7uIkbxnguDOS7Lqx+5ckSZIkSdLUM3k4Oz1RVUuq6mXAh4G/n8rOkmw6RLXFwHqTh1X1X6rqjiHalyRJkiRJ0gwzeTj7bQs8DJBk6yRXtNmItyc5tO1fnORfk5ye5MdJLkuyZW8jSTZJ8uUk/61tP5bkpCQ3Aq9I8rMkz2llI0mubq9PTHJWkiuT3JXkL1qTJwP7tBmSH0iyaZJPtnEtT3Jcq//bmY9JDkpyfRv/15Js3fafnOSOVu+TU/x+SpIkSZIkaUALZnoA6mvLJMuALYDnAa9u+1cCh1fVoy3Rd0OSC1vZjsCbq+ovknwVeAPwv1rZAuBs4EdV9Xdt31Zt+28Akkw0nt2BP2x1bktyMfAh4ISq+pNW/93Ai4A9qmp1kmf1NtDG+xHgwKr6dZL/CnwwySnA4cDOVVVJthvbeZKjgaMBFi1aNPE7J0mSJEmSpI3GmYez0+iy5Z2Bg4GvpMvuBfjvSZYD3wVeADy31bm3qpa117fQLSsedSrrJg4B1gBfH3A836qqJ6rqF8BVwF59jjkQ+EJVrQaoqhVjyv8Q2BW4riVGjwJeCDxKlxQ9I8mfAo+PbbiqTquqkaoa2X777QccsiRJkiRJkibL5OEsV1XXA88Btgfe2v7ds6qWAD+nm50IsKqn2hrWnVX6A+CAJFv07FtZVWt6tlfzu3joPQ6g1rMNXWKz3/7e8stbUnRJVe1aVe9qyca96BKZhwHfmaANSZIkSZIkTSOTh7Nckp2BTYFfAguBB6vqySQH0M3cG8QXgUuAryUZb6n6z4A92+s3jCk7NMkWSZ4N7A/cDPwK2KbnmMuAY0bbH7tsGbgB2DvJS1r5M5Ls1O57uLCqLgGOB5YMeE6SJEmSJEmaYt7zcHYavechdDP2jqqqNUnOBv4lyVJgGfCTQRusqn9MshA4K8lb+xzyUeCLSf4KuHFM2U3AxcAi4GNVdX+Sh4DVSX4IfAn4DLATsDzJk8DpwCk9/T+U5B3AOUk2b7s/QpeE/FabFRngA4OekyRJkiRJkqZWqiZaaar5LsmJwGNVNSuegjwyMlJLly6d6WFIkiRJkiTNGUluqaqRfmUuW5YkSZIkSZLUl8uWNaGqOnGmxyBJkiRJkqSZ4cxDSZIkSZIkSX2ZPJQkSZIkSZLUVTLKNwAACCdJREFUlw9M0dNKkl8Bd870OPS09BzgFzM9CD0tGTsalrGjYRk7Gpaxo2EZOxqWsTN3vLCqtu9X4D0P9XRz53hP/5EmkmSpsaNhGDsalrGjYRk7Gpaxo2EZOxqWsTM/uGxZkiRJkiRJUl8mDyVJkiRJkiT1ZfJQTzenzfQA9LRl7GhYxo6GZexoWMaOhmXsaFjGjoZl7MwDPjBFkiRJkiRJUl/OPJQkSZIkSZLUl8lDSZIkSZIkSX2ZPNSskeTgJHcm+WmSD/Up3zzJea38xiSLe8o+3PbfmeSPpnPcmnnDxk6SxUmeSLKs/XxhuseumTVA7Oyb5NYkq5McMabsqCR3tZ+jpm/UmmmTjJs1PdecC6dv1JoNBoidDya5I8nyJFckeWFPmdeceWySseN1Zx4bIHaOSXJ7i4/vJ9m1p8zvWPPYsLHjd6y5yXsealZIsinwb8BrgfuAm4E3V9UdPce8B9i9qo5JciRweFW9qV2kzgH2Ap4PfBfYqarWTPd5aPpNMnYWAxdV1W7TP3LNtAFjZzGwLXACcGFVnd/2PwtYCowABdwC7FlVD0/jKWgGTCZuWtljVbX1dI5Zs8OAsXMAcGNVPZ7k3cD+7f8rrznz2GRip5V53ZmnBoydbavq0fb69cB7qupgv2PNb5OMncX4HWvOceahZou9gJ9W1T1V9RvgXODQMcccCny5vT4feE2StP3nVtWqqroX+GlrT/PDZGJH89t6Y6eqflZVy4G1Y+r+EXB5Va1oX94vBw6ejkFrxk0mbjS/DRI7V1XV423zBuD322uvOfPbZGJH89sgsfNoz+ZWdH+gAL9jzXeTiR3NQSYPNVu8APi/Pdv3tX19j6mq1cAjwLMHrKu5azKxA/CiJLcluSbJPlM9WM0qk7l2eN2Zvyb72W+RZGmSG5IctnGHplluQ2PnXcC3h6yruWUysQNed+azgWInyXuT3A38A/C+DamrOWsysQN+x5pzFsz0AKSm3yywsX+5GO+YQepq7ppM7DwALKqqXybZE/hmkpeO+Sua5q7JXDu87sxfk/3sF1XV/UleDFyZ5PaqunsjjU2z28Cxk+RtdEuU99vQupqTJhM74HVnPhsodqrqs8Bnk7wF+Ahw1KB1NWdNJnb8jjUHOfNQs8V9wH/s2f594P7xjkmyAFgIrBiwruauoWOnLcP4JUBV3QLcDew05SPWbDGZa4fXnflrUp99Vd3f/r0HuBrYY2MOTrPaQLGT5EDgr4HXV9WqDamrOWsyseN1Z37b0GvHucDo7FSvO/Pb0LHjd6y5yeShZoubgR2TvCjJ7wFHAmOfBnch3V8yAI4ArqzuiT8XAkeme6Lui4AdgZumadyaeUPHTpLt282AaX+N3xG4Z5rGrZk3SOyM51LgoCTPTPJM4KC2T3Pf0HHT4mXz9vo5wN7AHRPX0hyy3thJsgdwKl3y58GeIq8589vQseN1Z94bJHZ27Nk8BLirvfY71vw2dOz4HWtuctmyZoWqWp3kWLpfhDcFzqyqHyc5CVhaVRcCXwTOSvJTuhmHR7a6P07yVbpfhFYD7/UpYPPHZGIH2Bc4KclqYA1wTFWtmP6z0EwYJHaSvBz4BvBM4HVJPlpVL62qFUk+RveLFcBJxs78MJm4AXYBTk2ylu4PuCf3PrVQc9uA/199Atga+Fp7rtf/qarXe82Z3yYTO3jdmdcGjJ1j26zVJ4GHaX9w9zvW/DaZ2MHvWHNSuolbkiRJkiRJkrQuly1LkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkiRJkqS+TB5KkiRJkiRJ6svkoSRJkuaNJI9Nc3+Lk7xlOvuUJEnamEweSpIkSVMgyQJgMWDyUJIkPW0tmOkBSJIkSdMtyf7AR4GfA0uAC4DbgfcDWwKHVdXdSb4ErAReCjwX+GBVXZRkC+DzwAiwuu2/Ksk7gEOALYCtgGcAuyRZBnwZ+AZwVisDOLaqftDGcyLwC2A34BbgbVVVSV4OfLrVWQW8BngcOBnYH9gc+GxVnbqx3ydJkiSTh5IkSZqvXgbsAqwA7gHOqKq9krwfOA44vh23GNgP2AG4KslLgPcCVNUfJNkZuCzJTu34VwC7V9WKlhQ8oar+BCDJM4DXVtXKJDsC59AlIAH2oEtS3g9cB+yd5CbgPOBNVXVzkm2BJ4B3AY9U1cuTbA5cl+Syqrp3Ct4nSZI0j5k8lCRJ0nx1c1U9AJDkbuCytv924ICe475aVWuBu5LcA+wMvAr4DEBV/STJvwOjycPLq2rFOH1uBpySZAmwpqcOwE1VdV8bzzK6pOUjwANVdXPr69FWfhCwe5IjWt2FwI6AyUNJkrRRmTyUJEnSfLWq5/Xanu21rPt7co2pV0AmaPfXE5R9gG6p9Mvo7j++cpzxrGljSJ/+afuPq6pLJ+hLkiRp0nxgiiRJkjSxNybZJMkOwIuBO4FrgbcCtOXKi9r+sX4FbNOzvZBuJuFa4O3Apuvp+yfA89t9D0myTXsQy6XAu5NsNjqGJFtN0I4kSdJQnHkoSZIkTexO4Bq6B6Yc0+5X+DngC0lup3tgyjuqalXylAmJy4HVSX4IfAn4HPD1JG8ErmLiWYpU1W+SvAn4TJIt6e53eCBwBt2y5lvTdfoQcNjGOFlJkqReqeq3CkKSJElSe9ryRVV1/kyPRZIkaSa4bFmSJEmSJElSX848lCRJkiRJktSXMw8lSZIkSZIk9WXyUJIkSZIkSVJfJg8lSZIkSZIk9WXyUJIkSZIkSVJfJg8lSZIkSZIk9fX/AbECZfRZK5XSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x306.72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "important_features_top = show_feature_importances(X_train_balanced.columns,\n",
    "                                                  model_xgb.feature_importances_, get_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Credit Score',\n",
       " 'Current Loan Amount',\n",
       " 'Annual Income',\n",
       " 'Monthly Debt',\n",
       " 'Number of Open Accounts',\n",
       " 'Maximum Open Credit',\n",
       " 'Current Credit Balance',\n",
       " 'Years of Credit History',\n",
       " 'Tax Liens',\n",
       " 'Number of Credit Problems']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGyl6MARaFLv"
   },
   "source": [
    "### Финальная модель<a class=\"anchor\" id=\"final_model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=1,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=21, reg_alpha=0,\n",
      "              reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=True,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69      1478\n",
      "           1       0.69      0.72      0.70      1478\n",
      "\n",
      "    accuracy                           0.70      2956\n",
      "   macro avg       0.70      0.70      0.70      2956\n",
      "weighted avg       0.70      0.70      0.70      2956\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      1617\n",
      "           1       0.42      0.67      0.51       633\n",
      "\n",
      "    accuracy                           0.64      2250\n",
      "   macro avg       0.62      0.65      0.62      2250\n",
      "weighted avg       0.71      0.64      0.66      2250\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0              0    1\n",
      "Credit Default           \n",
      "0               1028  589\n",
      "1                211  422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobapid3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "final_xgb = xgb.XGBClassifier(random_state=21, \n",
    "                              max_depth=1, \n",
    "                              reg_lambda=10\n",
    "                              )\n",
    "final_xgb.fit(X_train_balanced[important_features_top], y_train_balanced)\n",
    "\n",
    "evaluate_preds(final_xgb,\n",
    "               X_train_balanced[important_features_top],\n",
    "               X_test[important_features_top],\n",
    "               y_train_balanced,\n",
    "               y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLT836LbaFLz"
   },
   "source": [
    "### Сохранение финальной модели<a class=\"anchor\" id=\"final_model_saving\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Path(MODELS_PATH/'finalized_model.sav')\n",
    "pickle.dump(final_xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
